{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../train_test_splits/iteration_2/balanced_data_resampled_new.csv\")\n",
    "df = df.drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "\n",
    "X = df['sentences']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdropper = df\n",
    "split0 = dfdropper.sample(n=155, random_state = 1)\n",
    "dfdropper = dfdropper.drop(split0.index)\n",
    "\n",
    "split1 = dfdropper.sample(n=155, random_state = 1)\n",
    "dfdropper = dfdropper.drop(split1.index)\n",
    "\n",
    "split2 = dfdropper.sample(n=155, random_state = 1)\n",
    "dfdropper = dfdropper.drop(split2.index)\n",
    "\n",
    "split3 = dfdropper.sample(n=155, random_state = 1)\n",
    "dfdropper = dfdropper.drop(split3.index)\n",
    "\n",
    "split4 = dfdropper.sample(n=156, random_state = 1)\n",
    "dfdropper = dfdropper.drop(split4.index)\n",
    "\n",
    "\n",
    "split5 = dfdropper.sample(n=156, random_state = 1)\n",
    "dfdropper = dfdropper.drop(split5.index)\n",
    "\n",
    "split6 = dfdropper.sample(n=156, random_state = 1)\n",
    "dfdropper = dfdropper.drop(split6.index)\n",
    "\n",
    "split7 = dfdropper.sample(n=156, random_state = 1)\n",
    "dfdropper = dfdropper.drop(split7.index)\n",
    "\n",
    "split8 = dfdropper.sample(n=156, random_state = 1)\n",
    "dfdropper = dfdropper.drop(split8.index)\n",
    "\n",
    "split9 = dfdropper.sample(n=156, random_state = 1)\n",
    "\n",
    "\n",
    "'''split0 = df.iloc[0:178]\n",
    "split1 = df.iloc[178:356]\n",
    "split2 = df.iloc[356:534]\n",
    "split3 = df.iloc[534:712]\n",
    "split4 = df.iloc[712:890]\n",
    "split5 = df.iloc[890:1068]\n",
    "split6 = df.iloc[1068:1246]\n",
    "split7 = df.iloc[1246:1424]\n",
    "split8 = df.iloc[1424:1602]\n",
    "split9 = df.iloc[1602:]'''\n",
    "\n",
    "splits = [split0, split1, split2, split3, split4, split5, split6, split7, split8, split9]\n",
    "count = 0\n",
    "for split in splits:\n",
    "    split.to_csv('../train_test_splits/iteration_2/new_split' + str(count) + \".csv\")\n",
    "    count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from xml.sax.handler import feature_namespace_prefixes\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os\n",
    "import csv\n",
    "\n",
    "directory = '../train_test_splits/iteration_2/'\n",
    "testsplit = 'new_split0.csv'\n",
    "\n",
    "results_table = [['Model Name', 'Precision', 'Recall', 'F-1 Score']]\n",
    "\n",
    "nb_precision = []\n",
    "nb_recall = []\n",
    "nb_fscore = []\n",
    "\n",
    "rf_precision = []\n",
    "rf_recall = []\n",
    "rf_fscore = []\n",
    "\n",
    "knn_precision = []\n",
    "knn_recall = []\n",
    "knn_fscore = []\n",
    "\n",
    "lr_precision = []\n",
    "lr_recall = []\n",
    "lr_fscore = []\n",
    "\n",
    "dt_precision = []\n",
    "dt_recall = []\n",
    "dt_fscore = []\n",
    "\n",
    "svm_precision = []\n",
    "svm_recall = []\n",
    "svm_fscore = []\n",
    "\n",
    "per_precision = []\n",
    "per_recall = []\n",
    "per_fscore = []\n",
    "\n",
    "\n",
    "counter = 0\n",
    "for count in range(10):\n",
    "    \n",
    "    X_train = pd.DataFrame()\n",
    "    y_train = pd.DataFrame()\n",
    "    X_test = pd.DataFrame()\n",
    "    y_test = pd.DataFrame()\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename == \"balanced_data_resampled_new.csv\":\n",
    "            continue\n",
    "        if filename == testsplit:\n",
    "            test = pd.read_csv(os.path.join(directory, filename))\n",
    "            X_test = pd.concat([X_test, test['sentences']])\n",
    "            y_test = pd.concat([y_test, test['label']])\n",
    "        \n",
    "        else:\n",
    "            train = pd.read_csv(os.path.join(directory, filename))\n",
    "            X_train = pd.concat([X_train, train['sentences']])\n",
    "            y_train = pd.concat([y_train, train['label']])\n",
    "        #print(X_train.shape)\n",
    "        \n",
    "    #tf-idf vectorizer\n",
    "    vectorizer_tfidf = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "    train_tfIdf = vectorizer_tfidf.fit_transform(X_train[0].values.astype('U'))\n",
    "    test_tfIdf = vectorizer_tfidf.transform(X_test[0].values.astype('U'))\n",
    "    \n",
    "    #NaiveBayes\n",
    "    nb_classifier = MultinomialNB()\n",
    "    nb_classifier.fit(train_tfIdf, y_train[0])\n",
    "    pred = nb_classifier.predict(test_tfIdf) \n",
    "    cr_nb = classification_report(pred, y_test[0], output_dict=True)\n",
    "    #print(list(cr_nb['1.0'].values())[0:3], \"\\n\")\n",
    "    \n",
    "    res_nb = list(cr_nb['1.0'].values())\n",
    "    nb_precision.append(res_nb[0])\n",
    "    nb_recall.append(res_nb[1])\n",
    "    nb_fscore.append(res_nb[2])\n",
    "    \n",
    "\n",
    "    dict = {\n",
    "\n",
    "    \"sentences\": X_test[0],\n",
    "    \"prediction\": pred,\n",
    "    \"label\": y_test[0]\n",
    "\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(dict)\n",
    "    df.to_csv('test.csv', mode='a')\n",
    "    df_misclassified = df.loc[df[\"prediction\"] != df[\"label\"]]\n",
    "    # df_misclassified.to_csv('nb_misclassified.csv')\n",
    "    df_misclassified.to_csv(\"nb_misclassified.csv\", mode=\"a\", index = True, header=True)\n",
    "\n",
    "    \n",
    "    #Random Forest\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "    rf_classifier.fit(train_tfIdf, y_train[0])\n",
    "    predrf = rf_classifier.predict(test_tfIdf)\n",
    "    cr_rf = classification_report(predrf, y_test[0], output_dict=True)\n",
    "    #print(cr_rf['1.0'], \"\\n\")\n",
    "\n",
    "    res_rf = list(cr_rf['1.0'].values())\n",
    "    rf_precision.append(res_rf[0])\n",
    "    rf_recall.append(res_rf[1])\n",
    "    rf_fscore.append(res_rf[2])\n",
    "    \n",
    "    dict = {\n",
    "\n",
    "    \"sentences\": X_test[0],\n",
    "    \"prediction\": predrf,\n",
    "    \"label\": y_test[0]\n",
    "\n",
    "    }\n",
    "    \n",
    "    rf_df = pd.DataFrame(dict)\n",
    "    rf_df_misclassified = rf_df.loc[rf_df[\"prediction\"] != rf_df[\"label\"]]\n",
    "    rf_df_misclassified.to_csv(\"rf_misclassified.csv\", mode=\"a\", index = True, header=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #KNN\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors = 4)\n",
    "    knn_classifier.fit(train_tfIdf, y_train[0])\n",
    "    pred_knn = knn_classifier.predict(test_tfIdf) \n",
    "    cr_knn = classification_report(pred_knn, y_test[0], output_dict=True)\n",
    "    #print(cr_knn['1.0'], \"\\n\")\n",
    "\n",
    "    res_knn = list(cr_knn['1.0'].values())\n",
    "    knn_precision.append(res_knn[0])\n",
    "    knn_recall.append(res_knn[1])\n",
    "    knn_fscore.append(res_knn[2])\n",
    "    \n",
    "    dict = {\n",
    "\n",
    "    \"sentences\": X_test[0],\n",
    "    \"prediction\": pred_knn,\n",
    "    \"label\": y_test[0]\n",
    "\n",
    "    }\n",
    "    \n",
    "    knn_df = pd.DataFrame(dict)\n",
    "    knn_df_misclassified = knn_df.loc[knn_df[\"prediction\"] != knn_df[\"label\"]]\n",
    "    knn_df_misclassified.to_csv(\"knn_misclassified.csv\", mode=\"a\", index = True, header=True)\n",
    "    \n",
    "    #Logistic Regression\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(train_tfIdf, y_train[0])\n",
    "    pred_lr =  lr.predict(test_tfIdf)\n",
    "    cr_lr = classification_report(pred_lr, y_test[0], output_dict=True)\n",
    "    #print(cr_knn['1.0'], \"\\n\")\n",
    "\n",
    "    res_lr = list(cr_lr['1.0'].values())\n",
    "    lr_precision.append(res_lr[0])\n",
    "    lr_recall.append(res_lr[1])\n",
    "    lr_fscore.append(res_lr[2])\n",
    "    \n",
    "    dict = {\n",
    "\n",
    "    \"sentences\": X_test[0],\n",
    "    \"prediction\": pred_lr,\n",
    "    \"label\": y_test[0]\n",
    "\n",
    "    }\n",
    "    \n",
    "    \n",
    "    lr_df = pd.DataFrame(dict)\n",
    "    lr_df_misclassified = lr_df.loc[lr_df[\"prediction\"] != lr_df[\"label\"]]\n",
    "    lr_df_misclassified.to_csv(\"lr_misclassified.csv\", mode=\"a\", index = True, header=True)\n",
    "    \n",
    "\n",
    "    #Decision tree\n",
    "    dec_tree = tree.DecisionTreeClassifier()\n",
    "    dec_tree = dec_tree.fit(train_tfIdf, y_train[0])\n",
    "    pred_tree = dec_tree.predict(test_tfIdf)\n",
    "    cr_dt = classification_report(pred_tree, y_test[0], output_dict=True)\n",
    "\n",
    "    res_dt = list(cr_dt['1.0'].values())\n",
    "    #print(res_dt[0])\n",
    "    dt_precision.append(res_dt[0])\n",
    "    dt_recall.append(res_dt[1])\n",
    "    dt_fscore.append(res_dt[2])\n",
    "    \n",
    "    dict = {\n",
    "\n",
    "    \"sentences\": X_test[0],\n",
    "    \"prediction\": pred_tree,\n",
    "    \"label\": y_test[0]\n",
    "\n",
    "    }\n",
    "    \n",
    "    dt_df = pd.DataFrame(dict)\n",
    "    dt_df_misclassified = dt_df.loc[dt_df[\"prediction\"] != dt_df[\"label\"]]\n",
    "    dt_df_misclassified.to_csv(\"dTree_misclassified.csv\", mode=\"a\", index = True, header=True)\n",
    "\n",
    "    # SVM model\n",
    "    svm = SVC()\n",
    "    svm.fit(train_tfIdf, y_train[0])\n",
    "    pred_svm = svm.predict(test_tfIdf)\n",
    "    # cr_svm = classification_report(pred_svm, YTEST)\n",
    "    # print(cr_svm)\n",
    "    cr_svm = classification_report(pred_svm, y_test[0], output_dict=True)\n",
    "\n",
    "    res_svm = list(cr_svm['1.0'].values())\n",
    "    svm_precision.append(res_svm[0])\n",
    "    svm_recall.append(res_svm[1])\n",
    "    svm_fscore.append(res_svm[2])\n",
    "    \n",
    "    dict = {\n",
    "\n",
    "    \"sentences\": X_test[0],\n",
    "    \"prediction\": pred_svm,\n",
    "    \"label\": y_test[0]\n",
    "\n",
    "    }\n",
    "    \n",
    "    svm_df = pd.DataFrame(dict)\n",
    "    svm_df_misclassified = svm_df.loc[svm_df[\"prediction\"] != svm_df[\"label\"]]\n",
    "    svm_df_misclassified.to_csv(\"SVM_misclassified.csv\", mode=\"a\", index = True, header=True)\n",
    "\n",
    "    #perceptron model\n",
    "\n",
    "    perc = Perceptron(random_state=100)\n",
    "    perc.fit(train_tfIdf, y_train[0])\n",
    "    pred_per = perc.predict(test_tfIdf)\n",
    "\n",
    "    # cr_perc = classification_report(pred_perc, YTEST)\n",
    "    # print(cr_perc)\n",
    "    cr_per = classification_report(pred_per, y_test[0], output_dict=True)\n",
    "    \n",
    "    res_per = list(cr_per['1.0'].values())\n",
    "    per_precision.append(res_per[0])\n",
    "    per_recall.append(res_per[1])\n",
    "    per_fscore.append(res_per[2])\n",
    "    \n",
    "    dict = {\n",
    "\n",
    "    \"sentences\": X_test[0],\n",
    "    \"prediction\": pred_per,\n",
    "    \"label\": y_test[0]\n",
    "\n",
    "    }\n",
    "    \n",
    "    perc_df = pd.DataFrame(dict)\n",
    "    perc_df_misclassified = perc_df.loc[perc_df[\"prediction\"] != perc_df[\"label\"]]\n",
    "    perc_df_misclassified.to_csv(\"perc_misclassified.csv\", mode=\"a\", index = True, header=True)\n",
    "\n",
    "\n",
    "    #print(testsplit)\n",
    "\n",
    "    counter += 1\n",
    "    testsplit = 'new_split' + str(counter) + '.csv'\n",
    "\n",
    "results_table.append(['Naive Bayes', round(sum(nb_precision)/len(nb_precision), 3), round(sum(nb_recall)/len(nb_recall), 3), round(sum(nb_fscore)/len(nb_fscore), 3)])\n",
    "results_table.append(['Random Forest', round(sum(rf_precision)/len(rf_precision), 3), round(sum(rf_recall)/len(rf_recall), 3), round(sum(rf_fscore)/len(rf_fscore), 3)])\n",
    "results_table.append(['KNN', round(sum(knn_precision)/len(knn_precision), 3), round(sum(knn_recall)/len(knn_recall), 3), round(sum(knn_fscore)/len(knn_fscore), 3)])\n",
    "results_table.append(['Logistic Regression', round(sum(lr_precision)/len(lr_precision), 3), round(sum(lr_recall)/len(lr_recall), 3), round(sum(lr_fscore)/len(lr_fscore), 3)])\n",
    "results_table.append(['Decision Tree', round(sum(dt_precision)/len(dt_precision), 3), round(sum(dt_recall)/len(dt_recall), 3), round(sum(dt_fscore)/len(dt_fscore), 3)])\n",
    "results_table.append(['SVM', round(sum(svm_precision)/len(svm_precision), 3), round(sum(svm_recall)/len(svm_recall), 3), round(sum(svm_fscore)/len(svm_fscore), 3)])\n",
    "results_table.append(['Perceptron', round(sum(per_precision)/len(per_precision), 3), round(sum(per_recall)/len(per_recall), 3), round(sum(per_fscore)/len(per_fscore), 3)])\n",
    "  \n",
    "with open(\"results_iteration2.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(results_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentences</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>From 2012 to 2020, we achieved a 26% reduction...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>In 2021, we achieved a 9% absolute emissions r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>This reduction was partially driven by energy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>In 2021, 9.6% of our purchased electricity cam...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>A large portion of this renewable electricity ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>1777</td>\n",
       "      <td>13</td>\n",
       "      <td>As the largest  U.S. utility company, we know ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>1778</td>\n",
       "      <td>14</td>\n",
       "      <td>Carbon- intensive companies, especially  have ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>1779</td>\n",
       "      <td>15</td>\n",
       "      <td>01  The decarbonization milestones with  proje...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>1780</td>\n",
       "      <td>16</td>\n",
       "      <td>Years before many Fortune  500 companies consi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>1781</td>\n",
       "      <td>17</td>\n",
       "      <td>We can help make any such goal  achievable, af...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1782 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  Unnamed: 0  \\\n",
       "0                0           0   \n",
       "1                1           1   \n",
       "2                2           2   \n",
       "3                3           3   \n",
       "4                4           4   \n",
       "...            ...         ...   \n",
       "1777          1777          13   \n",
       "1778          1778          14   \n",
       "1779          1779          15   \n",
       "1780          1780          16   \n",
       "1781          1781          17   \n",
       "\n",
       "                                              sentences  label  \n",
       "0     From 2012 to 2020, we achieved a 26% reduction...      1  \n",
       "1     In 2021, we achieved a 9% absolute emissions r...      1  \n",
       "2     This reduction was partially driven by energy ...      1  \n",
       "3     In 2021, 9.6% of our purchased electricity cam...      1  \n",
       "4     A large portion of this renewable electricity ...      1  \n",
       "...                                                 ...    ...  \n",
       "1777  As the largest  U.S. utility company, we know ...      0  \n",
       "1778  Carbon- intensive companies, especially  have ...      0  \n",
       "1779  01  The decarbonization milestones with  proje...      0  \n",
       "1780  Years before many Fortune  500 companies consi...      0  \n",
       "1781  We can help make any such goal  achievable, af...      0  \n",
       "\n",
       "[1782 rows x 4 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old_labeled = pd.read_csv(\"../train_test_splits/balanced_data_resampled.csv\")\n",
    "# old_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>label</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From 2012 to 2020, we achieved a 26% reduction...</td>\n",
       "      <td>1</td>\n",
       "      <td>EliLilly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In 2021, we achieved a 9% absolute emissions r...</td>\n",
       "      <td>1</td>\n",
       "      <td>EliLilly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This reduction was partially driven by energy ...</td>\n",
       "      <td>1</td>\n",
       "      <td>EliLilly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 2021, 9.6% of our purchased electricity cam...</td>\n",
       "      <td>1</td>\n",
       "      <td>EliLilly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A large portion of this renewable electricity ...</td>\n",
       "      <td>1</td>\n",
       "      <td>EliLilly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>And we want to  bring the U.S. economy  with u...</td>\n",
       "      <td>0</td>\n",
       "      <td>NextEraEnergyZeroCarbonBlueprint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>We  would stand with you and help  accelerate ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NextEraEnergyZeroCarbonBlueprint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>Real Zero means zero scope 1  direct emissions...</td>\n",
       "      <td>0</td>\n",
       "      <td>NextEraEnergyZeroCarbonBlueprint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>Years before many Fortune  500 companies consi...</td>\n",
       "      <td>0</td>\n",
       "      <td>NextEraEnergyZeroCarbonBlueprint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>Real Zero™ means  eliminating carbon  emission...</td>\n",
       "      <td>0</td>\n",
       "      <td>NextEraEnergyZeroCarbonBlueprint</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1780 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentences  label  \\\n",
       "0     From 2012 to 2020, we achieved a 26% reduction...      1   \n",
       "1     In 2021, we achieved a 9% absolute emissions r...      1   \n",
       "2     This reduction was partially driven by energy ...      1   \n",
       "3     In 2021, 9.6% of our purchased electricity cam...      1   \n",
       "4     A large portion of this renewable electricity ...      1   \n",
       "...                                                 ...    ...   \n",
       "1775  And we want to  bring the U.S. economy  with u...      0   \n",
       "1776  We  would stand with you and help  accelerate ...      0   \n",
       "1777  Real Zero means zero scope 1  direct emissions...      0   \n",
       "1778  Years before many Fortune  500 companies consi...      0   \n",
       "1779  Real Zero™ means  eliminating carbon  emission...      0   \n",
       "\n",
       "                               company  \n",
       "0                             EliLilly  \n",
       "1                             EliLilly  \n",
       "2                             EliLilly  \n",
       "3                             EliLilly  \n",
       "4                             EliLilly  \n",
       "...                                ...  \n",
       "1775  NextEraEnergyZeroCarbonBlueprint  \n",
       "1776  NextEraEnergyZeroCarbonBlueprint  \n",
       "1777  NextEraEnergyZeroCarbonBlueprint  \n",
       "1778  NextEraEnergyZeroCarbonBlueprint  \n",
       "1779  NextEraEnergyZeroCarbonBlueprint  \n",
       "\n",
       "[1780 rows x 3 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_match(df, old_labeled_df):\n",
    "\n",
    "#     ''' \n",
    "#     find match between sentence and a sentence in the old labeled df. \n",
    "#     apply the old label back to the appropriate df sentence\n",
    "#     '''\n",
    "\n",
    "#     # count = 0\n",
    "#     for x, sentence in enumerate(df['sentences']):\n",
    "\n",
    "#         for i, old_sentence in enumerate(old_labeled_df['sentences']):\n",
    "\n",
    "#             if sentence == old_sentence:\n",
    "#                 # print(sentence)\n",
    "#                 # print(old_sentence)\n",
    "#                 # print(\"========================\")\n",
    "#                 # print(old_labeled_df['sentences'][0])\n",
    "#                 # print(i)\n",
    "#                 if old_labeled_df['label'][i] == 1:\n",
    "#                     df['label'][x] = 1\n",
    "#                 else:\n",
    "#                     df['label'][x] = 0\n",
    "\n",
    "#     return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/21/c38b7fjj2vd3z7p6w475vgz80000gn/T/ipykernel_54903/3677169794.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['label'][x] = 1\n",
      "/var/folders/21/c38b7fjj2vd3z7p6w475vgz80000gn/T/ipykernel_54903/3677169794.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['label'][x] = 0\n"
     ]
    }
   ],
   "source": [
    "# old_label_new_split = find_match(orig, old_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_label_new_split.to_csv(\"old_label_new_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "db1c1e886ca7e5218f158543d1b9804c0a5c522f5654be9e23cd8543b350db84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
