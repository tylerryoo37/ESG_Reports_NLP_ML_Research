{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "329b5117",
   "metadata": {},
   "source": [
    "### List of Companies to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ce9861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xml.sax.handler import feature_namespace_prefixes\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1669b135",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_list = [\"EliLilly\", \"Merck\", \"BristolMyersSquibb\", \"johnsonandjohnson\", \"Abbott\", \"Boeing\",\n",
    "             \"UPS\", \"3M\", \"Walmart\", \"Tesla\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134b712e",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc16f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tylerryoo/t3/summarizer_test_result/test_all_sentences'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "912b22ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = pd.read_csv(\"../../relevant_irrelevant_sentences_labeled_final/all_sentences.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35072376",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = all_sentences[all_sentences.label == 'rel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8348f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "irr = all_sentences[all_sentences.label == 'irr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bca4b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevant = irr\n",
    "relevant = rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0e1679d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>sentences</th>\n",
       "      <th>company_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>In 2021, 9.6% of our purchased electricity cam...</td>\n",
       "      <td>EliLilly</td>\n",
       "      <td>rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A large portion of this renewable electricity ...</td>\n",
       "      <td>EliLilly</td>\n",
       "      <td>rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>From 2012 to 2020, we achieved a 26% reduction...</td>\n",
       "      <td>EliLilly</td>\n",
       "      <td>rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>In 2021, we achieved a 9% absolute emissions r...</td>\n",
       "      <td>EliLilly</td>\n",
       "      <td>rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>This reduction was partially driven by energy ...</td>\n",
       "      <td>EliLilly</td>\n",
       "      <td>rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>867</td>\n",
       "      <td>2017 Retired and demolished 250 MW of coal, re...</td>\n",
       "      <td>NextEraEnergyZeroCarbonBlueprint</td>\n",
       "      <td>rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>868</td>\n",
       "      <td>2018 Retired and demolished 636 MW of coal and...</td>\n",
       "      <td>NextEraEnergyZeroCarbonBlueprint</td>\n",
       "      <td>rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>869</td>\n",
       "      <td>2019 Aquired Gulf Power, which added 1,750 MW ...</td>\n",
       "      <td>NextEraEnergyZeroCarbonBlueprint</td>\n",
       "      <td>rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>870</td>\n",
       "      <td>2020 Retired 615 MW of nuclear and 330 MW of c...</td>\n",
       "      <td>NextEraEnergyZeroCarbonBlueprint</td>\n",
       "      <td>rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>871</td>\n",
       "      <td>2021 Added 2,008 MW of wind, 1,547 MW of solar...</td>\n",
       "      <td>NextEraEnergyZeroCarbonBlueprint</td>\n",
       "      <td>rel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>871 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     key                                          sentences  \\\n",
       "1      1  In 2021, 9.6% of our purchased electricity cam...   \n",
       "2      2  A large portion of this renewable electricity ...   \n",
       "3      3  From 2012 to 2020, we achieved a 26% reduction...   \n",
       "4      4  In 2021, we achieved a 9% absolute emissions r...   \n",
       "5      5  This reduction was partially driven by energy ...   \n",
       "..   ...                                                ...   \n",
       "867  867  2017 Retired and demolished 250 MW of coal, re...   \n",
       "868  868  2018 Retired and demolished 636 MW of coal and...   \n",
       "869  869  2019 Aquired Gulf Power, which added 1,750 MW ...   \n",
       "870  870  2020 Retired 615 MW of nuclear and 330 MW of c...   \n",
       "871  871  2021 Added 2,008 MW of wind, 1,547 MW of solar...   \n",
       "\n",
       "                        company_label label  \n",
       "1                            EliLilly   rel  \n",
       "2                            EliLilly   rel  \n",
       "3                            EliLilly   rel  \n",
       "4                            EliLilly   rel  \n",
       "5                            EliLilly   rel  \n",
       "..                                ...   ...  \n",
       "867  NextEraEnergyZeroCarbonBlueprint   rel  \n",
       "868  NextEraEnergyZeroCarbonBlueprint   rel  \n",
       "869  NextEraEnergyZeroCarbonBlueprint   rel  \n",
       "870  NextEraEnergyZeroCarbonBlueprint   rel  \n",
       "871  NextEraEnergyZeroCarbonBlueprint   rel  \n",
       "\n",
       "[871 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdea939a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_irrelevant: 76406\n",
      "total_relevant: 871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c8/4mvtm2vs4_vdgzz_n030prfm0000gn/T/ipykernel_70237/1501945674.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  irrelevant[\"class\"] = 0\n",
      "/var/folders/c8/4mvtm2vs4_vdgzz_n030prfm0000gn/T/ipykernel_70237/1501945674.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  relevant[\"class\"] = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>sentences</th>\n",
       "      <th>company_label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>571</td>\n",
       "      <td>ACHIEVED: 60% reduction Use electricity genera...</td>\n",
       "      <td>Cisco</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>489</td>\n",
       "      <td>Amazon has contracted 82 MW of the new 120- MW...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>204</td>\n",
       "      <td>â€¢ At the Zeeland refinery, the Company plans t...</td>\n",
       "      <td>Total</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>623</td>\n",
       "      <td>Our commitment is that by 2030, 100 percent of...</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>840</td>\n",
       "      <td>The strategy proposes adding approximately 16 ...</td>\n",
       "      <td>AEP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     key                                          sentences company_label  \\\n",
       "571  571  ACHIEVED: 60% reduction Use electricity genera...         Cisco   \n",
       "489  489  Amazon has contracted 82 MW of the new 120- MW...        Amazon   \n",
       "204  204  â€¢ At the Zeeland refinery, the Company plans t...         Total   \n",
       "623  623  Our commitment is that by 2030, 100 percent of...     Microsoft   \n",
       "840  840  The strategy proposes adding approximately 16 ...           AEP   \n",
       "\n",
       "     class  \n",
       "571      1  \n",
       "489      1  \n",
       "204      1  \n",
       "623      1  \n",
       "840      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull in the csv data\n",
    "# irrelevant = pd.read_csv(\"../../relevant_irrelevant_sentences_labeled/extracted_irrelevant_sentences.csv\")\n",
    "# relevant = pd.read_csv(\"../../relevant_irrelevant_sentences_labeled/extracted_relevant_sentences.csv\")\n",
    "irrelevant = irr\n",
    "relevant = rel\n",
    "\n",
    "print(\"total_irrelevant:\", len(irrelevant))\n",
    "print(\"total_relevant:\", len(relevant))\n",
    "irrelevant[\"class\"] = 0\n",
    "relevant[\"class\"] = 1\n",
    "\n",
    "irrelevant = irrelevant[['key','sentences', 'company_label', 'class']]\n",
    "relevant = relevant[['key','sentences', 'company_label', 'class']]\n",
    "relevant.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40b4df3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EliLilly \n",
      " 84 15 76322 856\n",
      "Merck \n",
      " 2384 10 74022 861\n",
      "BristolMyersSquibb \n",
      " 1172 4 75234 867\n",
      "johnsonandjohnson \n",
      " 1917 13 74489 858\n",
      "Abbott \n",
      " 2030 8 74376 863\n",
      "Boeing \n",
      " 1134 7 75272 864\n",
      "UPS \n",
      " 75 11 76331 860\n",
      "3M \n",
      " 3202 5 73204 866\n",
      "Walmart \n",
      " 560 3 75846 868\n",
      "Tesla \n",
      " 1364 3 75042 868\n"
     ]
    }
   ],
   "source": [
    "for comp_name in comp_list:\n",
    "    comp_irrelevant = irrelevant[irrelevant['company_label'] == comp_name]\n",
    "    comp_relevant = relevant[relevant['company_label'] == comp_name]\n",
    "    comp_all = pd.concat([comp_relevant,comp_irrelevant])\n",
    "    \n",
    "    comp_all.to_csv(comp_name + '_comp_all_data.csv', encoding = 'utf-8-sig')\n",
    "    \n",
    "    rest_irrelevant = irrelevant[irrelevant['company_label'] != comp_name]\n",
    "    rest_relevant = relevant[relevant['company_label'] != comp_name]\n",
    "    \n",
    "    print(comp_name, \"\\n\", len(comp_irrelevant), len(comp_relevant),len(rest_irrelevant), len(rest_relevant))\n",
    "    \n",
    "    comp_sample_irr = comp_irrelevant.sample(n = len(comp_relevant), random_state = 1)\n",
    "    rest_sample_irr = rest_irrelevant.sample(n = len(rest_relevant), random_state = 1)\n",
    "    \n",
    "    comp_balanced_set = pd.concat([comp_relevant, comp_sample_irr], ignore_index = True)\n",
    "    rest_balanced_set = pd.concat([rest_relevant, rest_sample_irr], ignore_index = True)\n",
    "    \n",
    "    # Train Test Split on comp_balanced_set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(comp_balanced_set['sentences'], \n",
    "                                                        comp_balanced_set['class'], test_size=0.1, random_state=100)\n",
    "\n",
    "    dfbalanced = pd.concat([comp_balanced_set], ignore_index=True)\n",
    "    dfbalanced.to_csv(comp_name + '_comp_balanced_data.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "    dfbalanced_train = pd.concat([X_train.to_frame(), y_train.to_frame()], axis = 1, ignore_index = True)\n",
    "    dfbalanced_train.columns = ['sentences', 'class']\n",
    "    dfbalanced_train.to_csv(comp_name + '_comp_balanced_data_train.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "    dfbalanced_test = pd.concat([X_test.to_frame(), y_test.to_frame()], axis = 1, ignore_index = True)\n",
    "    dfbalanced_test.columns = ['sentences', 'class']\n",
    "    dfbalanced_test.to_csv(comp_name + '_comp_balanced_data_test.csv', encoding = 'utf-8-sig')\n",
    "    \n",
    "    # Train Test Split on rest_balanced_set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(rest_balanced_set['sentences'], \n",
    "                                                        rest_balanced_set['class'], test_size=0.1, random_state=100)\n",
    "\n",
    "    dfbalanced = pd.concat([rest_balanced_set], ignore_index=True)\n",
    "    dfbalanced.to_csv(comp_name + '_rest_balanced_data.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "    dfbalanced_train = pd.concat([X_train.to_frame(), y_train.to_frame()], axis = 1, ignore_index = True)\n",
    "    dfbalanced_train.columns = ['sentences', 'class']\n",
    "    dfbalanced_train.to_csv(comp_name + '_rest_balanced_data_train.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "    dfbalanced_test = pd.concat([X_test.to_frame(), y_test.to_frame()], axis = 1, ignore_index = True)\n",
    "    dfbalanced_test.columns = ['sentences', 'class']\n",
    "    dfbalanced_test.to_csv(comp_name + '_rest_balanced_data_test.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9345bd7e",
   "metadata": {},
   "source": [
    "### Move Files to a Separate Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4ce51bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f058aae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tylerryoo/t3/summarizer_test_result/test_all_sentences'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc475e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir_name = 'balanced_data'\n",
    "new_dir = pathlib.Path('/Users/tylerryoo/t3/summarizer_test_result/test_all_sentences/', new_dir_name)\n",
    "new_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "559db7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/tylerryoo/t3/summarizer_test_result/test_all_sentences'\n",
    "files = glob.glob(path + \"/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daae7288",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    \n",
    "    if file.startswith('/Users/tylerryoo/t3/summarizer_test_result/test_all_sentences/test_sentences_'):\n",
    "        continue\n",
    "        \n",
    "    filename = file.split('/')[-1]\n",
    "    \n",
    "    target = (r'/Users/tylerryoo/t3/summarizer_test_result/test_all_sentences/' + new_dir_name + '/' + filename)\n",
    "\n",
    "    shutil.move(file, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c1dd1a",
   "metadata": {},
   "source": [
    "### Logistics Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70587332",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_list = [\"EliLilly\", \"Merck\", \"BristolMyersSquibb\", \"johnsonandjohnson\", \"Abbott\", \"Boeing\",\n",
    "             \"UPS\", \"3M\", \"Walmart\", \"Tesla\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "196f679e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>sentences</th>\n",
       "      <th>company_label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>These projects will address approximately 35 p...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>These agreements follow a 2018 U.S. wind VPPA,...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>Approximately nine percent of our total Scope ...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>Our company recently signed three virtual powe...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>Over 50 percent of the vehicles being utilized...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>62636</td>\n",
       "      <td>Carbon dioxide and other plants caused approxi...</td>\n",
       "      <td>Linde</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>60835</td>\n",
       "      <td>We describe the rights and responsibilities of...</td>\n",
       "      <td>Prologis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>32208</td>\n",
       "      <td>3TGs â€“ Tin, tantalum, tungsten, and gold Aeros...</td>\n",
       "      <td>Philip_Morris_Intl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>44196</td>\n",
       "      <td>People and Culture Employee Engagement</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>48441</td>\n",
       "      <td>N/A N/A 14 Franchises Not relevant NIKE does n...</td>\n",
       "      <td>Nike</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1712 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        key                                          sentences  \\\n",
       "0        16  These projects will address approximately 35 p...   \n",
       "1        17  These agreements follow a 2018 U.S. wind VPPA,...   \n",
       "2        18  Approximately nine percent of our total Scope ...   \n",
       "3        19  Our company recently signed three virtual powe...   \n",
       "4        20  Over 50 percent of the vehicles being utilized...   \n",
       "...     ...                                                ...   \n",
       "1707  62636  Carbon dioxide and other plants caused approxi...   \n",
       "1708  60835  We describe the rights and responsibilities of...   \n",
       "1709  32208  3TGs â€“ Tin, tantalum, tungsten, and gold Aeros...   \n",
       "1710  44196             People and Culture Employee Engagement   \n",
       "1711  48441  N/A N/A 14 Franchises Not relevant NIKE does n...   \n",
       "\n",
       "           company_label  class  \n",
       "0                  Merck      1  \n",
       "1                  Merck      1  \n",
       "2                  Merck      1  \n",
       "3                  Merck      1  \n",
       "4                  Merck      1  \n",
       "...                  ...    ...  \n",
       "1707               Linde      0  \n",
       "1708            Prologis      0  \n",
       "1709  Philip_Morris_Intl      0  \n",
       "1710               Tesla      0  \n",
       "1711                Nike      0  \n",
       "\n",
       "[1712 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('balanced_data/EliLilly_rest_balanced_data.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bb1113d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EliLilly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.66        41\n",
      "           1       1.00      0.26      0.41        58\n",
      "\n",
      "    accuracy                           0.57        99\n",
      "   macro avg       0.74      0.63      0.53        99\n",
      "weighted avg       0.79      0.57      0.51        99\n",
      "\n",
      "\n",
      "\n",
      "Merck\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      2227\n",
      "           1       1.00      0.06      0.11       167\n",
      "\n",
      "    accuracy                           0.93      2394\n",
      "   macro avg       0.97      0.53      0.54      2394\n",
      "weighted avg       0.94      0.93      0.91      2394\n",
      "\n",
      "\n",
      "\n",
      "BristolMyersSquibb\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1115\n",
      "           1       0.75      0.05      0.09        61\n",
      "\n",
      "    accuracy                           0.95      1176\n",
      "   macro avg       0.85      0.52      0.53      1176\n",
      "weighted avg       0.94      0.95      0.93      1176\n",
      "\n",
      "\n",
      "\n",
      "johnsonandjohnson\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1847\n",
      "           1       0.77      0.12      0.21        83\n",
      "\n",
      "    accuracy                           0.96      1930\n",
      "   macro avg       0.87      0.56      0.59      1930\n",
      "weighted avg       0.95      0.96      0.95      1930\n",
      "\n",
      "\n",
      "\n",
      "Abbott\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1919\n",
      "           1       1.00      0.07      0.13       119\n",
      "\n",
      "    accuracy                           0.95      2038\n",
      "   macro avg       0.97      0.53      0.55      2038\n",
      "weighted avg       0.95      0.95      0.92      2038\n",
      "\n",
      "\n",
      "\n",
      "Boeing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      1013\n",
      "           1       1.00      0.05      0.10       128\n",
      "\n",
      "    accuracy                           0.89      1141\n",
      "   macro avg       0.95      0.53      0.52      1141\n",
      "weighted avg       0.91      0.89      0.85      1141\n",
      "\n",
      "\n",
      "\n",
      "UPS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        67\n",
      "           1       1.00      0.58      0.73        19\n",
      "\n",
      "    accuracy                           0.91        86\n",
      "   macro avg       0.95      0.79      0.84        86\n",
      "weighted avg       0.92      0.91      0.90        86\n",
      "\n",
      "\n",
      "\n",
      "3M\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      3006\n",
      "           1       1.00      0.02      0.05       201\n",
      "\n",
      "    accuracy                           0.94      3207\n",
      "   macro avg       0.97      0.51      0.51      3207\n",
      "weighted avg       0.94      0.94      0.91      3207\n",
      "\n",
      "\n",
      "\n",
      "Walmart\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98       533\n",
      "           1       1.00      0.10      0.18        30\n",
      "\n",
      "    accuracy                           0.95       563\n",
      "   macro avg       0.98      0.55      0.58       563\n",
      "weighted avg       0.95      0.95      0.93       563\n",
      "\n",
      "\n",
      "\n",
      "Tesla\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90      1116\n",
      "           1       1.00      0.01      0.02       251\n",
      "\n",
      "    accuracy                           0.82      1367\n",
      "   macro avg       0.91      0.51      0.46      1367\n",
      "weighted avg       0.85      0.82      0.74      1367\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train on rest data and fit on comp data \n",
    "crLR_reports = []\n",
    "\n",
    "for comp in comp_list:\n",
    "    train = pd.read_csv('balanced_data/' + comp + \"_rest_balanced_data_train.csv\", index_col = 0)\n",
    "    test = pd.read_csv('balanced_data/' + comp + \"_rest_balanced_data_test.csv\", index_col = 0)\n",
    "    \n",
    "    X_train = train['sentences']\n",
    "    X_test = test['sentences']\n",
    "\n",
    "    y_train = train['class']\n",
    "    y_test = test['class']\n",
    "    \n",
    "    comp_X_test = pd.read_csv('balanced_data/' + comp + \"_comp_balanced_data.csv\")['sentences']\n",
    "    comp_Y_test = pd.read_csv('balanced_data/' + comp + \"_comp_balanced_data.csv\")['class']\n",
    "    \n",
    "    \n",
    "    vectorizer_tfidf = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "\n",
    "    train_tfIdf = vectorizer_tfidf.fit_transform(X_train.values.astype('U'))\n",
    "\n",
    "    # testing on balanced comp sentences \n",
    "    test_tfIdf_comp = vectorizer_tfidf.transform(comp_X_test.values.astype('U'))\n",
    "    \n",
    "    # testing on all comp sentences\n",
    "    comp_all_X_test = pd.read_csv('balanced_data/' + comp + \"_comp_all_data.csv\")['sentences']\n",
    "    comp_all_Y_test = pd.read_csv('balanced_data/' + comp + \"_comp_all_data.csv\")['class']\n",
    "    comp_key = pd.read_csv('balanced_data/' + comp + \"_comp_all_data.csv\")['key']\n",
    "    \n",
    "    test_all_tfIdf_comp = vectorizer_tfidf.transform(comp_all_X_test.values.astype('U'))\n",
    "    \n",
    "    # logistic regression prediction and evaluation\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    \n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(train_tfIdf, y_train)\n",
    "    predLR =  lr.predict(test_all_tfIdf_comp)\n",
    "\n",
    "#     nb_classifier = MultinomialNB()\n",
    "#     nb_classifier.fit(train_tfIdf, y_train)\n",
    "#     predLR = nb_classifier.predict(test_all_tfIdf_comp) \n",
    "\n",
    "    crLR = classification_report(predLR, comp_all_Y_test)\n",
    "    print(comp)\n",
    "    print(crLR)\n",
    "    print(\"\\n\")\n",
    "    crLR = classification_report(predLR, comp_all_Y_test, output_dict=True)\n",
    "    \n",
    "    # update the classification report as it's printed\n",
    "    crLR.update({\"accuracy\": {\"precision\": None, \"recall\": None, \"f1-score\": crLR[\"accuracy\"], \"support\": crLR['macro avg']['support']}})\n",
    "    df = pd.DataFrame(crLR).transpose()\n",
    "    df.index.name = comp\n",
    "    crLR_reports.append(df)\n",
    "    \n",
    "    df = pd.DataFrame([comp_key.to_list(), comp_all_X_test.to_list(), comp_all_Y_test.to_list(), list(predLR)]).transpose()\n",
    "    df = df.rename(columns = { 0: 'key', 1: 'sentences', 2: 'class', 3: 'predicted'})\n",
    "    df.to_csv('test_sentences_' + comp + '.csv', encoding = 'utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfc40e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_3M = pd.read_csv('test_sentences_3M.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69b1b03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentences\n",
       "class           \n",
       "0           3202\n",
       "1              5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_3M.groupby('class').count()[['sentences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57e4f238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentences\n",
       "predicted           \n",
       "0               3006\n",
       "1                201"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_3M.groupby('predicted').count()[['sentences']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ad687f",
   "metadata": {},
   "source": [
    "### Printing the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d54fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(crLR_reports, keys=map(lambda d: d.index.name, crLR_reports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8145bc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.names = [None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bca7c58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4daad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.support = df.support.apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9b0b3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">EliLilly</th>\n",
       "      <th>0</th>\n",
       "      <td>0.49</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.41</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.57</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.53</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.51</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Merck</th>\n",
       "      <th>0</th>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>2394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">BristolMyersSquibb</th>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">johnsonandjohnson</th>\n",
       "      <th>0</th>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.21</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Abbott</th>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.13</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Boeing</th>\n",
       "      <th>0</th>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">UPS</th>\n",
       "      <th>0</th>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.73</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.91</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.84</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3M</th>\n",
       "      <th>0</th>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>3006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94</td>\n",
       "      <td>3207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>3207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "      <td>3207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Walmart</th>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.18</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.95</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.58</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Tesla</th>\n",
       "      <th>0</th>\n",
       "      <td>0.82</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 precision  recall  f1-score  support\n",
       "EliLilly           0                  0.49    1.00      0.66       41\n",
       "                   1                  1.00    0.26      0.41       58\n",
       "                   accuracy            NaN     NaN      0.57       99\n",
       "                   macro avg          0.74    0.63      0.53       99\n",
       "                   weighted avg       0.79    0.57      0.51       99\n",
       "Merck              0                  0.93    1.00      0.97     2227\n",
       "                   1                  1.00    0.06      0.11      167\n",
       "                   accuracy            NaN     NaN      0.93     2394\n",
       "                   macro avg          0.97    0.53      0.54     2394\n",
       "                   weighted avg       0.94    0.93      0.91     2394\n",
       "BristolMyersSquibb 0                  0.95    1.00      0.97     1115\n",
       "                   1                  0.75    0.05      0.09       61\n",
       "                   accuracy            NaN     NaN      0.95     1176\n",
       "                   macro avg          0.85    0.52      0.53     1176\n",
       "                   weighted avg       0.94    0.95      0.93     1176\n",
       "johnsonandjohnson  0                  0.96    1.00      0.98     1847\n",
       "                   1                  0.77    0.12      0.21       83\n",
       "                   accuracy            NaN     NaN      0.96     1930\n",
       "                   macro avg          0.87    0.56      0.59     1930\n",
       "                   weighted avg       0.95    0.96      0.95     1930\n",
       "Abbott             0                  0.95    1.00      0.97     1919\n",
       "                   1                  1.00    0.07      0.13      119\n",
       "                   accuracy            NaN     NaN      0.95     2038\n",
       "                   macro avg          0.97    0.53      0.55     2038\n",
       "                   weighted avg       0.95    0.95      0.92     2038\n",
       "Boeing             0                  0.89    1.00      0.94     1013\n",
       "                   1                  1.00    0.05      0.10      128\n",
       "                   accuracy            NaN     NaN      0.89     1141\n",
       "                   macro avg          0.95    0.53      0.52     1141\n",
       "                   weighted avg       0.91    0.89      0.85     1141\n",
       "UPS                0                  0.89    1.00      0.94       67\n",
       "                   1                  1.00    0.58      0.73       19\n",
       "                   accuracy            NaN     NaN      0.91       86\n",
       "                   macro avg          0.95    0.79      0.84       86\n",
       "                   weighted avg       0.92    0.91      0.90       86\n",
       "3M                 0                  0.94    1.00      0.97     3006\n",
       "                   1                  1.00    0.02      0.05      201\n",
       "                   accuracy            NaN     NaN      0.94     3207\n",
       "                   macro avg          0.97    0.51      0.51     3207\n",
       "                   weighted avg       0.94    0.94      0.91     3207\n",
       "Walmart            0                  0.95    1.00      0.98      533\n",
       "                   1                  1.00    0.10      0.18       30\n",
       "                   accuracy            NaN     NaN      0.95      563\n",
       "                   macro avg          0.98    0.55      0.58      563\n",
       "                   weighted avg       0.95    0.95      0.93      563\n",
       "Tesla              0                  0.82    1.00      0.90     1116\n",
       "                   1                  1.00    0.01      0.02      251\n",
       "                   accuracy            NaN     NaN      0.82     1367\n",
       "                   macro avg          0.91    0.51      0.46     1367\n",
       "                   weighted avg       0.85    0.82      0.74     1367"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "538e2e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"summarizer_test_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a568f55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "db1c1e886ca7e5218f158543d1b9804c0a5c522f5654be9e23cd8543b350db84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
