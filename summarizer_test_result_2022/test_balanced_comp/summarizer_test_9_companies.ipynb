{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "329b5117",
   "metadata": {},
   "source": [
    "### List of Companies to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ce9861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xml.sax.handler import feature_namespace_prefixes\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1669b135",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_list = [\"EliLilly\", \"Merck\", \"BristolMyersSquibb\", \"johnsonandjohnson\", \"Abbott\", \"Boeing\",\n",
    "             \"UPS\", \"3M\", \"Walmart\", \"Tesla\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134b712e",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdea939a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_irrelevant: 78258\n",
      "total_relevant: 891\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevant_sentences</th>\n",
       "      <th>company_label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>While our combined Scope 1 and 2 emissions dec...</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>We also implemented a more accurate method for...</td>\n",
       "      <td>Shell</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>It halved its operated methane emissions betwe...</td>\n",
       "      <td>Total</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>13.5 13.0 2009 2010 2011 2012 2013 2014 2015 2...</td>\n",
       "      <td>Delta</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>All In Europe, electricity will be provided by...</td>\n",
       "      <td>Total</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    relevant_sentences company_label  class\n",
       "609  While our combined Scope 1 and 2 emissions dec...     Microsoft      1\n",
       "333  We also implemented a more accurate method for...         Shell      1\n",
       "235  It halved its operated methane emissions betwe...         Total      1\n",
       "143  13.5 13.0 2009 2010 2011 2012 2013 2014 2015 2...         Delta      1\n",
       "232  All In Europe, electricity will be provided by...         Total      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull in the csv data\n",
    "irrelevant = pd.read_csv(\"../relevant_irrelevant_sentences_labeled/extracted_irrelevant_sentences.csv\")\n",
    "relevant = pd.read_csv(\"../relevant_irrelevant_sentences_labeled/extracted_relevant_sentences.csv\")\n",
    "\n",
    "print(\"total_irrelevant:\", len(irrelevant))\n",
    "print(\"total_relevant:\", len(relevant))\n",
    "irrelevant[\"class\"] = 0\n",
    "relevant[\"class\"] = 1\n",
    "\n",
    "irrelevant = irrelevant[['relevant_sentences', 'company_label', 'class']]\n",
    "relevant = relevant[['relevant_sentences', 'company_label', 'class']]\n",
    "relevant.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40b4df3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EliLilly \n",
      " 84 15 78174 876\n",
      "Merck \n",
      " 2437 11 75821 880\n",
      "BristolMyersSquibb \n",
      " 1185 4 77073 887\n",
      "johnsonandjohnson \n",
      " 2056 13 76202 878\n",
      "Abbott \n",
      " 2123 8 76135 883\n",
      "Boeing \n",
      " 1158 7 77100 884\n",
      "UPS \n",
      " 75 11 78183 880\n",
      "3M \n",
      " 3272 8 74986 883\n",
      "Walmart \n",
      " 588 3 77670 888\n",
      "Tesla \n",
      " 1396 3 76862 888\n"
     ]
    }
   ],
   "source": [
    "for comp_name in comp_list:\n",
    "    comp_irrelevant = irrelevant[irrelevant['company_label'] == comp_name]\n",
    "    comp_relevant = relevant[relevant['company_label'] == comp_name]\n",
    "    \n",
    "    rest_irrelevant = irrelevant[irrelevant['company_label'] != comp_name]\n",
    "    rest_relevant = relevant[relevant['company_label'] != comp_name]\n",
    "    \n",
    "    print(comp_name, \"\\n\", len(comp_irrelevant), len(comp_relevant),len(rest_irrelevant), len(rest_relevant))\n",
    "    \n",
    "    comp_sample_irr = comp_irrelevant.sample(n = len(comp_relevant), random_state = 1)\n",
    "    rest_sample_irr = rest_irrelevant.sample(n = len(rest_relevant), random_state = 1)\n",
    "    \n",
    "    comp_balanced_set = pd.concat([comp_relevant, comp_sample_irr], ignore_index = True)\n",
    "    rest_balanced_set = pd.concat([rest_relevant, rest_sample_irr], ignore_index = True)\n",
    "    \n",
    "    # Train Test Split on comp_balanced_set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(comp_balanced_set['relevant_sentences'], \n",
    "                                                        comp_balanced_set['class'], test_size=0.1, random_state=100)\n",
    "\n",
    "    dfbalanced = pd.concat([comp_balanced_set], ignore_index=True)\n",
    "    dfbalanced.to_csv(comp_name + '_comp_balanced_data.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "    dfbalanced_train = pd.concat([X_train.to_frame(), y_train.to_frame()], axis = 1, ignore_index = True)\n",
    "    dfbalanced_train.columns = ['sentences', 'class']\n",
    "    dfbalanced_train.to_csv(comp_name + '_comp_balanced_data_train.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "    dfbalanced_test = pd.concat([X_test.to_frame(), y_test.to_frame()], axis = 1, ignore_index = True)\n",
    "    dfbalanced_test.columns = ['sentences', 'class']\n",
    "    dfbalanced_test.to_csv(comp_name + '_comp_balanced_data_test.csv', encoding = 'utf-8-sig')\n",
    "    \n",
    "    # Train Test Split on rest_balanced_set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(rest_balanced_set['relevant_sentences'], \n",
    "                                                        rest_balanced_set['class'], test_size=0.1, random_state=100)\n",
    "\n",
    "    dfbalanced = pd.concat([rest_balanced_set], ignore_index=True)\n",
    "    dfbalanced.to_csv(comp_name + '_rest_balanced_data.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "    dfbalanced_train = pd.concat([X_train.to_frame(), y_train.to_frame()], axis = 1, ignore_index = True)\n",
    "    dfbalanced_train.columns = ['sentences', 'class']\n",
    "    dfbalanced_train.to_csv(comp_name + '_rest_balanced_data_train.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "    dfbalanced_test = pd.concat([X_test.to_frame(), y_test.to_frame()], axis = 1, ignore_index = True)\n",
    "    dfbalanced_test.columns = ['sentences', 'class']\n",
    "    dfbalanced_test.to_csv(comp_name + '_rest_balanced_data_test.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c1dd1a",
   "metadata": {},
   "source": [
    "### Logistics Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70587332",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_list = [\"EliLilly\", \"Merck\", \"BristolMyersSquibb\", \"johnsonandjohnson\", \"Abbott\", \"Boeing\",\n",
    "             \"UPS\", \"3M\", \"Walmart\", \"Tesla\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "196f679e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>relevant_sentences</th>\n",
       "      <th>company_label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>These projects will address approximately 35 p...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>These agreements follow a 2018 U.S. wind VPPA,...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Our company recently signed three virtual powe...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Over 50 percent of the vehicles being utilized...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Approximately nine percent of our total Scope ...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>1747</td>\n",
       "      <td>2   Reported operating income grew 35%, declin...</td>\n",
       "      <td>CocaCola</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>1748</td>\n",
       "      <td>Regular Training and Reviews  Providing ongoin...</td>\n",
       "      <td>Mondelez_Intl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>1749</td>\n",
       "      <td>After a rigorous review and vetting  process, ...</td>\n",
       "      <td>ThermoFisherScientifiic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>1750</td>\n",
       "      <td>We collect genetic and genomic samples in our ...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>1751</td>\n",
       "      <td>In 2021 SnackFutures™ applied  its investment ...</td>\n",
       "      <td>Mondelez_Intl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1752 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                 relevant_sentences  \\\n",
       "0              0  These projects will address approximately 35 p...   \n",
       "1              1  These agreements follow a 2018 U.S. wind VPPA,...   \n",
       "2              2  Our company recently signed three virtual powe...   \n",
       "3              3  Over 50 percent of the vehicles being utilized...   \n",
       "4              4  Approximately nine percent of our total Scope ...   \n",
       "...          ...                                                ...   \n",
       "1747        1747  2   Reported operating income grew 35%, declin...   \n",
       "1748        1748  Regular Training and Reviews  Providing ongoin...   \n",
       "1749        1749  After a rigorous review and vetting  process, ...   \n",
       "1750        1750  We collect genetic and genomic samples in our ...   \n",
       "1751        1751  In 2021 SnackFutures™ applied  its investment ...   \n",
       "\n",
       "                company_label  class  \n",
       "0                       Merck      1  \n",
       "1                       Merck      1  \n",
       "2                       Merck      1  \n",
       "3                       Merck      1  \n",
       "4                       Merck      1  \n",
       "...                       ...    ...  \n",
       "1747                 CocaCola      0  \n",
       "1748            Mondelez_Intl      0  \n",
       "1749  ThermoFisherScientifiic      0  \n",
       "1750                    Merck      0  \n",
       "1751            Mondelez_Intl      0  \n",
       "\n",
       "[1752 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('EliLilly_rest_balanced_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7bb1113d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EliLilly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72        10\n",
      "           1       0.93      0.70      0.80        20\n",
      "\n",
      "    accuracy                           0.77        30\n",
      "   macro avg       0.77      0.80      0.76        30\n",
      "weighted avg       0.82      0.77      0.77        30\n",
      "\n",
      "\n",
      "\n",
      "Merck\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        12\n",
      "           1       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.95        22\n",
      "   macro avg       0.95      0.96      0.95        22\n",
      "weighted avg       0.96      0.95      0.95        22\n",
      "\n",
      "\n",
      "\n",
      "BristolMyersSquibb\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         6\n",
      "           1       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.75      0.83      0.73         8\n",
      "weighted avg       0.88      0.75      0.77         8\n",
      "\n",
      "\n",
      "\n",
      "johnsonandjohnson\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93        15\n",
      "           1       0.85      1.00      0.92        11\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.92      0.93      0.92        26\n",
      "weighted avg       0.93      0.92      0.92        26\n",
      "\n",
      "\n",
      "\n",
      "Abbott\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "\n",
      "\n",
      "Boeing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93         8\n",
      "           1       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.93      0.94      0.93        14\n",
      "weighted avg       0.94      0.93      0.93        14\n",
      "\n",
      "\n",
      "\n",
      "UPS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76        10\n",
      "           1       0.82      0.75      0.78        12\n",
      "\n",
      "    accuracy                           0.77        22\n",
      "   macro avg       0.77      0.78      0.77        22\n",
      "weighted avg       0.78      0.77      0.77        22\n",
      "\n",
      "\n",
      "\n",
      "3M\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "\n",
      "\n",
      "Walmart\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n",
      "\n",
      "\n",
      "Tesla\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train on rest data and fit on comp data \n",
    "crLR_reports = []\n",
    "\n",
    "for comp in comp_list: \n",
    "    train = pd.read_csv(comp + \"_rest_balanced_data_train.csv\")\n",
    "    test = pd.read_csv(comp + \"_rest_balanced_data_test.csv\")\n",
    "    \n",
    "    train.drop(columns = ['Unnamed: 0'])\n",
    "    test.drop(columns = ['Unnamed: 0'])\n",
    "    \n",
    "    X_train = train['sentences']\n",
    "    X_test = test['sentences']\n",
    "\n",
    "    y_train = train['class']\n",
    "    y_test = test['class']\n",
    "    \n",
    "    comp_X_test = pd.read_csv(comp + \"_comp_balanced_data.csv\")['relevant_sentences']\n",
    "    comp_Y_test = pd.read_csv(comp + \"_comp_balanced_data.csv\")['class']\n",
    "    \n",
    "    \n",
    "    vectorizer_tfidf = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "\n",
    "    train_tfIdf = vectorizer_tfidf.fit_transform(X_train.values.astype('U'))\n",
    "\n",
    "    test_tfIdf_comp = vectorizer_tfidf.transform(comp_X_test.values.astype('U'))\n",
    "    \n",
    "    # logistic regression prediction and evaluation\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(train_tfIdf, y_train)\n",
    "\n",
    "\n",
    "    predLR =  lr.predict(test_tfIdf_comp)\n",
    "\n",
    "    crLR = classification_report(predLR, comp_Y_test)\n",
    "    print(comp)\n",
    "    print(crLR)\n",
    "    print(\"\\n\")\n",
    "    crLR = classification_report(predLR, comp_Y_test, output_dict=True)\n",
    "    \n",
    "    df = pd.DataFrame(crLR).transpose()\n",
    "    df.index.name = comp\n",
    "    crLR_reports.append(df)\n",
    "    \n",
    "    df = pd.DataFrame([comp_X_test.to_list(), comp_Y_test.to_list(), list(predLR)]).transpose()\n",
    "    df = df.rename(columns = { 0: 'sentences', 1: 'class', 2: 'predicted'})\n",
    "    df.to_csv('test_sentences_' + comp + '.csv', encoding = 'utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ad687f",
   "metadata": {},
   "source": [
    "### Printing the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0d54fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(crLR_reports, keys=map(lambda d: d.index.name, crLR_reports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8145bc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.names = [None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bca7c58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f4daad89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">EliLilly</th>\n",
       "      <th>0</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.72</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.80</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.76</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Merck</th>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.96</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">BristolMyersSquibb</th>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.80</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.73</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.77</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">johnsonandjohnson</th>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.93</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.85</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Abbott</th>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Boeing</th>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.86</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">UPS</th>\n",
       "      <th>0</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.76</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.78</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3M</th>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Walmart</th>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Tesla</th>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 precision  recall  f1-score  support\n",
       "EliLilly           0                  0.60    0.90      0.72    10.00\n",
       "                   1                  0.93    0.70      0.80    20.00\n",
       "                   accuracy           0.77    0.77      0.77     0.77\n",
       "                   macro avg          0.77    0.80      0.76    30.00\n",
       "                   weighted avg       0.82    0.77      0.77    30.00\n",
       "Merck              0                  1.00    0.92      0.96    12.00\n",
       "                   1                  0.91    1.00      0.95    10.00\n",
       "                   accuracy           0.95    0.95      0.95     0.95\n",
       "                   macro avg          0.95    0.96      0.95    22.00\n",
       "                   weighted avg       0.96    0.95      0.95    22.00\n",
       "BristolMyersSquibb 0                  1.00    0.67      0.80     6.00\n",
       "                   1                  0.50    1.00      0.67     2.00\n",
       "                   accuracy           0.75    0.75      0.75     0.75\n",
       "                   macro avg          0.75    0.83      0.73     8.00\n",
       "                   weighted avg       0.88    0.75      0.77     8.00\n",
       "johnsonandjohnson  0                  1.00    0.87      0.93    15.00\n",
       "                   1                  0.85    1.00      0.92    11.00\n",
       "                   accuracy           0.92    0.92      0.92     0.92\n",
       "                   macro avg          0.92    0.93      0.92    26.00\n",
       "                   weighted avg       0.93    0.92      0.92    26.00\n",
       "Abbott             0                  1.00    1.00      1.00     8.00\n",
       "                   1                  1.00    1.00      1.00     8.00\n",
       "                   accuracy           1.00    1.00      1.00     1.00\n",
       "                   macro avg          1.00    1.00      1.00    16.00\n",
       "                   weighted avg       1.00    1.00      1.00    16.00\n",
       "Boeing             0                  1.00    0.88      0.93     8.00\n",
       "                   1                  0.86    1.00      0.92     6.00\n",
       "                   accuracy           0.93    0.93      0.93     0.93\n",
       "                   macro avg          0.93    0.94      0.93    14.00\n",
       "                   weighted avg       0.94    0.93      0.93    14.00\n",
       "UPS                0                  0.73    0.80      0.76    10.00\n",
       "                   1                  0.82    0.75      0.78    12.00\n",
       "                   accuracy           0.77    0.77      0.77     0.77\n",
       "                   macro avg          0.77    0.78      0.77    22.00\n",
       "                   weighted avg       0.78    0.77      0.77    22.00\n",
       "3M                 0                  1.00    1.00      1.00     8.00\n",
       "                   1                  1.00    1.00      1.00     8.00\n",
       "                   accuracy           1.00    1.00      1.00     1.00\n",
       "                   macro avg          1.00    1.00      1.00    16.00\n",
       "                   weighted avg       1.00    1.00      1.00    16.00\n",
       "Walmart            0                  1.00    1.00      1.00     3.00\n",
       "                   1                  1.00    1.00      1.00     3.00\n",
       "                   accuracy           1.00    1.00      1.00     1.00\n",
       "                   macro avg          1.00    1.00      1.00     6.00\n",
       "                   weighted avg       1.00    1.00      1.00     6.00\n",
       "Tesla              0                  1.00    1.00      1.00     3.00\n",
       "                   1                  1.00    1.00      1.00     3.00\n",
       "                   accuracy           1.00    1.00      1.00     1.00\n",
       "                   macro avg          1.00    1.00      1.00     6.00\n",
       "                   weighted avg       1.00    1.00      1.00     6.00"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "538e2e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"summarizer_test_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432454cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
