{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "329b5117",
   "metadata": {},
   "source": [
    "### List of Companies to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4ce9861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xml.sax.handler import feature_namespace_prefixes\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1669b135",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_list = [\"EliLilly\", \"Merck\", \"BristolMyersSquibb\", \"johnsonandjohnson\", \"Abbott\", \"Boeing\",\n",
    "             \"UPS\", \"3M\", \"Walmart\", \"Tesla\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134b712e",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7dc16f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tylerryoo/t3/summarizer_test_result/test_all_sentences'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "912b22ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_sentences = pd.read_csv(\"../../relevant_irrelevant_sentences_labeled_final/all_sentences.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c787be45",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_sentences = pd.read_csv(\"../../extracted_sentences/notebooks/final_extracted_statistics_notebooks/rel_with_index.csv\", index_col = 0, dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d6541837",
   "metadata": {},
   "outputs": [],
   "source": [
    "irr_sentences = pd.read_csv(\"../../extracted_sentences/notebooks/final_extracted_statistics_notebooks/irr_with_index.csv\", index_col = 0, dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "35072376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel = all_sentences[all_sentences.label == 'rel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8348f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# irr = all_sentences[all_sentences.label == 'irr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bca4b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevant = irr_sentences\n",
    "relevant = rel_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4fc5352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant = relevant.rename(columns = {'relevant_sentences': 'sentences'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f9113399",
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevant = irrelevant.rename(columns = {'all_sentences': 'sentences'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "72ed54c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant['key'] = relevant[\"company_index\"] + relevant['sent_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4f8b075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevant['key'] = irrelevant[\"company_index\"] + irrelevant['sent_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e6d3b5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>sent_count_x</th>\n",
       "      <th>rel_match_all</th>\n",
       "      <th>sent_count_y</th>\n",
       "      <th>company_label</th>\n",
       "      <th>company_index</th>\n",
       "      <th>sent_index</th>\n",
       "      <th>label</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 2021, 9.6% of our purchased electricity cam...</td>\n",
       "      <td>11</td>\n",
       "      <td>Looking toward the future, we have set climate...</td>\n",
       "      <td>40</td>\n",
       "      <td>EliLilly</td>\n",
       "      <td>0001</td>\n",
       "      <td>0020</td>\n",
       "      <td>rel</td>\n",
       "      <td>00010020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A large portion of this renewable electricity ...</td>\n",
       "      <td>24</td>\n",
       "      <td>A large portion of this renewable electricity ...</td>\n",
       "      <td>24</td>\n",
       "      <td>EliLilly</td>\n",
       "      <td>0001</td>\n",
       "      <td>0021</td>\n",
       "      <td>rel</td>\n",
       "      <td>00010021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From 2012 to 2020, we achieved a 26% reduction...</td>\n",
       "      <td>12</td>\n",
       "      <td>From 2012 to 2020, we achieved a 26% reduction...</td>\n",
       "      <td>12</td>\n",
       "      <td>EliLilly</td>\n",
       "      <td>0001</td>\n",
       "      <td>0025</td>\n",
       "      <td>rel</td>\n",
       "      <td>00010025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 2021, we achieved a 9% absolute emissions r...</td>\n",
       "      <td>11</td>\n",
       "      <td>In 2021, we achieved a 9% absolute emissions r...</td>\n",
       "      <td>11</td>\n",
       "      <td>EliLilly</td>\n",
       "      <td>0001</td>\n",
       "      <td>0026</td>\n",
       "      <td>rel</td>\n",
       "      <td>00010026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This reduction was partially driven by energy ...</td>\n",
       "      <td>27</td>\n",
       "      <td>This reduction was partially driven by energy ...</td>\n",
       "      <td>27</td>\n",
       "      <td>EliLilly</td>\n",
       "      <td>0001</td>\n",
       "      <td>0027</td>\n",
       "      <td>rel</td>\n",
       "      <td>00010027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences sent_count_x  \\\n",
       "0  In 2021, 9.6% of our purchased electricity cam...           11   \n",
       "1  A large portion of this renewable electricity ...           24   \n",
       "2  From 2012 to 2020, we achieved a 26% reduction...           12   \n",
       "3  In 2021, we achieved a 9% absolute emissions r...           11   \n",
       "4  This reduction was partially driven by energy ...           27   \n",
       "\n",
       "                                       rel_match_all sent_count_y  \\\n",
       "0  Looking toward the future, we have set climate...           40   \n",
       "1  A large portion of this renewable electricity ...           24   \n",
       "2  From 2012 to 2020, we achieved a 26% reduction...           12   \n",
       "3  In 2021, we achieved a 9% absolute emissions r...           11   \n",
       "4  This reduction was partially driven by energy ...           27   \n",
       "\n",
       "  company_label company_index sent_index label       key  \n",
       "0      EliLilly          0001       0020   rel  00010020  \n",
       "1      EliLilly          0001       0021   rel  00010021  \n",
       "2      EliLilly          0001       0025   rel  00010025  \n",
       "3      EliLilly          0001       0026   rel  00010026  \n",
       "4      EliLilly          0001       0027   rel  00010027  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "15838f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>company_label</th>\n",
       "      <th>company_index</th>\n",
       "      <th>sent_index</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>label</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7/7/22, 10:29 AM Environmental | 2021 ESG Repo...</td>\n",
       "      <td>EliLilly</td>\n",
       "      <td>0001</td>\n",
       "      <td>0001</td>\n",
       "      <td>30</td>\n",
       "      <td>irr</td>\n",
       "      <td>00010001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making medicines requires the use of valuable ...</td>\n",
       "      <td>EliLilly</td>\n",
       "      <td>0001</td>\n",
       "      <td>0002</td>\n",
       "      <td>14</td>\n",
       "      <td>irr</td>\n",
       "      <td>00010002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We’re committed to reducing our environmental ...</td>\n",
       "      <td>EliLilly</td>\n",
       "      <td>0001</td>\n",
       "      <td>0003</td>\n",
       "      <td>18</td>\n",
       "      <td>irr</td>\n",
       "      <td>00010003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To track our progress, we measure and manage e...</td>\n",
       "      <td>EliLilly</td>\n",
       "      <td>0001</td>\n",
       "      <td>0004</td>\n",
       "      <td>27</td>\n",
       "      <td>irr</td>\n",
       "      <td>00010004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lilly manages health, safety and the environme...</td>\n",
       "      <td>EliLilly</td>\n",
       "      <td>0001</td>\n",
       "      <td>0005</td>\n",
       "      <td>13</td>\n",
       "      <td>irr</td>\n",
       "      <td>00010005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences company_label  \\\n",
       "0  7/7/22, 10:29 AM Environmental | 2021 ESG Repo...      EliLilly   \n",
       "1  Making medicines requires the use of valuable ...      EliLilly   \n",
       "2  We’re committed to reducing our environmental ...      EliLilly   \n",
       "3  To track our progress, we measure and manage e...      EliLilly   \n",
       "4  Lilly manages health, safety and the environme...      EliLilly   \n",
       "\n",
       "  company_index sent_index sent_count label       key  \n",
       "0          0001       0001         30   irr  00010001  \n",
       "1          0001       0002         14   irr  00010002  \n",
       "2          0001       0003         18   irr  00010003  \n",
       "3          0001       0004         27   irr  00010004  \n",
       "4          0001       0005         13   irr  00010005  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irrelevant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bdea939a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_irrelevant: 76410\n",
      "total_relevant: 912\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>sentences</th>\n",
       "      <th>company_label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55839</th>\n",
       "      <td>00530004</td>\n",
       "      <td>Against the backdrop of loss this year, we saw...</td>\n",
       "      <td>VIsa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23549</th>\n",
       "      <td>00220975</td>\n",
       "      <td>Embedding sustainability In this section Susta...</td>\n",
       "      <td>BP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>00710330</td>\n",
       "      <td>This network collaborates to provide results o...</td>\n",
       "      <td>AEP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73961</th>\n",
       "      <td>00700276</td>\n",
       "      <td>ENVIRONMENTAL Seizing the opportunity   to del...</td>\n",
       "      <td>Duke_Energy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61954</th>\n",
       "      <td>00591391</td>\n",
       "      <td>Linde is dependent upon its highly skilled, ex...</td>\n",
       "      <td>Linde</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            key                                          sentences  \\\n",
       "55839  00530004  Against the backdrop of loss this year, we saw...   \n",
       "23549  00220975  Embedding sustainability In this section Susta...   \n",
       "74999  00710330  This network collaborates to provide results o...   \n",
       "73961  00700276  ENVIRONMENTAL Seizing the opportunity   to del...   \n",
       "61954  00591391  Linde is dependent upon its highly skilled, ex...   \n",
       "\n",
       "      company_label  class  \n",
       "55839          VIsa      0  \n",
       "23549            BP      0  \n",
       "74999           AEP      0  \n",
       "73961   Duke_Energy      0  \n",
       "61954         Linde      0  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull in the csv data\n",
    "# irrelevant = pd.read_csv(\"../../relevant_irrelevant_sentences_labeled/extracted_irrelevant_sentences.csv\")\n",
    "# relevant = pd.read_csv(\"../../relevant_irrelevant_sentences_labeled/extracted_relevant_sentences.csv\")\n",
    "\n",
    "print(\"total_irrelevant:\", len(irrelevant))\n",
    "print(\"total_relevant:\", len(relevant))\n",
    "irrelevant[\"class\"] = 0\n",
    "relevant[\"class\"] = 1\n",
    "\n",
    "irrelevant = irrelevant[['key','sentences', 'company_label', 'class']]\n",
    "relevant = relevant[['key','sentences', 'company_label', 'class']]\n",
    "relevant.sample(5)\n",
    "irrelevant.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "40b4df3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EliLilly \n",
      " 84 15 76326 897\n",
      "Merck \n",
      " 2384 11 74026 901\n",
      "BristolMyersSquibb \n",
      " 1173 5 75237 907\n",
      "johnsonandjohnson \n",
      " 1917 13 74493 899\n",
      "Abbott \n",
      " 2030 8 74380 904\n",
      "Boeing \n",
      " 1134 8 75276 904\n",
      "UPS \n",
      " 74 12 76336 900\n",
      "3M \n",
      " 3202 6 73208 906\n",
      "Walmart \n",
      " 560 3 75850 909\n",
      "Tesla \n",
      " 1363 4 75047 908\n"
     ]
    }
   ],
   "source": [
    "for comp_name in comp_list:\n",
    "    comp_irrelevant = irrelevant[irrelevant['company_label'] == comp_name]\n",
    "    comp_relevant = relevant[relevant['company_label'] == comp_name]\n",
    "    comp_all = pd.concat([comp_relevant,comp_irrelevant])\n",
    "    \n",
    "    comp_all.to_csv(comp_name + '_comp_all_data.csv', encoding = 'utf-8-sig')\n",
    "    \n",
    "    rest_irrelevant = irrelevant[irrelevant['company_label'] != comp_name]\n",
    "    rest_relevant = relevant[relevant['company_label'] != comp_name]\n",
    "    \n",
    "    print(comp_name, \"\\n\", len(comp_irrelevant), len(comp_relevant),len(rest_irrelevant), len(rest_relevant))\n",
    "    \n",
    "    comp_sample_irr = comp_irrelevant.sample(n = len(comp_relevant), random_state = 1)\n",
    "    rest_sample_irr = rest_irrelevant.sample(n = len(rest_relevant), random_state = 1)\n",
    "    \n",
    "    comp_balanced_set = pd.concat([comp_relevant, comp_sample_irr], ignore_index = True)\n",
    "    rest_balanced_set = pd.concat([rest_relevant, rest_sample_irr], ignore_index = True)\n",
    "    \n",
    "    # Train Test Split on comp_balanced_set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(comp_balanced_set['sentences'], \n",
    "                                                        comp_balanced_set['class'], test_size=0.1, random_state=100)\n",
    "\n",
    "    dfbalanced = pd.concat([comp_balanced_set], ignore_index=True)\n",
    "    dfbalanced.to_csv(comp_name + '_comp_balanced_data.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "    dfbalanced_train = pd.concat([X_train.to_frame(), y_train.to_frame()], axis = 1, ignore_index = True)\n",
    "    dfbalanced_train.columns = ['sentences', 'class']\n",
    "    dfbalanced_train.to_csv(comp_name + '_comp_balanced_data_train.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "    dfbalanced_test = pd.concat([X_test.to_frame(), y_test.to_frame()], axis = 1, ignore_index = True)\n",
    "    dfbalanced_test.columns = ['sentences', 'class']\n",
    "    dfbalanced_test.to_csv(comp_name + '_comp_balanced_data_test.csv', encoding = 'utf-8-sig')\n",
    "    \n",
    "    # Train Test Split on rest_balanced_set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(rest_balanced_set['sentences'], \n",
    "                                                        rest_balanced_set['class'], test_size=0.1, random_state=100)\n",
    "\n",
    "    dfbalanced = pd.concat([rest_balanced_set], ignore_index=True)\n",
    "    dfbalanced.to_csv(comp_name + '_rest_balanced_data.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "    dfbalanced_train = pd.concat([X_train.to_frame(), y_train.to_frame()], axis = 1, ignore_index = True)\n",
    "    dfbalanced_train.columns = ['sentences', 'class']\n",
    "    dfbalanced_train.to_csv(comp_name + '_rest_balanced_data_train.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "    dfbalanced_test = pd.concat([X_test.to_frame(), y_test.to_frame()], axis = 1, ignore_index = True)\n",
    "    dfbalanced_test.columns = ['sentences', 'class']\n",
    "    dfbalanced_test.to_csv(comp_name + '_rest_balanced_data_test.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9345bd7e",
   "metadata": {},
   "source": [
    "### Move Files to a Separate Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d4ce51bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f058aae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tylerryoo/t3/summarizer_test_result/test_all_sentences'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cc475e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir_name = 'balanced_data'\n",
    "new_dir = pathlib.Path('/Users/tylerryoo/t3/summarizer_test_result/test_all_sentences/', new_dir_name)\n",
    "new_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "559db7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/tylerryoo/t3/summarizer_test_result/test_all_sentences'\n",
    "files = glob.glob(path + \"/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "daae7288",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    \n",
    "    if file.startswith('/Users/tylerryoo/t3/summarizer_test_result/test_all_sentences/test_sentences_'):\n",
    "        continue\n",
    "        \n",
    "    filename = file.split('/')[-1]\n",
    "    \n",
    "    target = (r'/Users/tylerryoo/t3/summarizer_test_result/test_all_sentences/' + new_dir_name + '/' + filename)\n",
    "\n",
    "    shutil.move(file, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c1dd1a",
   "metadata": {},
   "source": [
    "### Logistics Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "70587332",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_list = [\"EliLilly\", \"Merck\", \"BristolMyersSquibb\", \"johnsonandjohnson\", \"Abbott\", \"Boeing\",\n",
    "             \"UPS\", \"3M\", \"Walmart\", \"Tesla\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "196f679e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>sentences</th>\n",
       "      <th>company_label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31178</td>\n",
       "      <td>In 2020, a new solar array was installed at on...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31179</td>\n",
       "      <td>These projects will address approximately 35 p...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31180</td>\n",
       "      <td>These agreements follow a 2018 U.S. wind VPPA,...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31181</td>\n",
       "      <td>Approximately nine percent of our total Scope ...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31185</td>\n",
       "      <td>40 percent of our U.S. fleet are now partial-z...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>210497</td>\n",
       "      <td>Occasional, or non-routine, flaring connected ...</td>\n",
       "      <td>Total</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>700357</td>\n",
       "      <td>For  example, we have partnered with TerraPowe...</td>\n",
       "      <td>Duke_Energy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>610584</td>\n",
       "      <td>• “Managers treat our employees with dignity a...</td>\n",
       "      <td>SherwinWilliams</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>682718</td>\n",
       "      <td>Discussion of long-term and short-term strateg...</td>\n",
       "      <td>Dow</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>321100</td>\n",
       "      <td>2 Systemwide total based on estimated total use.</td>\n",
       "      <td>CocaCola</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1794 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         key                                          sentences  \\\n",
       "0      31178  In 2020, a new solar array was installed at on...   \n",
       "1      31179  These projects will address approximately 35 p...   \n",
       "2      31180  These agreements follow a 2018 U.S. wind VPPA,...   \n",
       "3      31181  Approximately nine percent of our total Scope ...   \n",
       "4      31185  40 percent of our U.S. fleet are now partial-z...   \n",
       "...      ...                                                ...   \n",
       "1789  210497  Occasional, or non-routine, flaring connected ...   \n",
       "1790  700357  For  example, we have partnered with TerraPowe...   \n",
       "1791  610584  • “Managers treat our employees with dignity a...   \n",
       "1792  682718  Discussion of long-term and short-term strateg...   \n",
       "1793  321100   2 Systemwide total based on estimated total use.   \n",
       "\n",
       "        company_label  class  \n",
       "0               Merck      1  \n",
       "1               Merck      1  \n",
       "2               Merck      1  \n",
       "3               Merck      1  \n",
       "4               Merck      1  \n",
       "...               ...    ...  \n",
       "1789            Total      0  \n",
       "1790      Duke_Energy      0  \n",
       "1791  SherwinWilliams      0  \n",
       "1792              Dow      0  \n",
       "1793         CocaCola      0  \n",
       "\n",
       "[1794 rows x 4 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('balanced_data/EliLilly_rest_balanced_data.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7bb1113d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EliLilly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      1.00      0.63        39\n",
      "           1       1.00      0.25      0.40        60\n",
      "\n",
      "    accuracy                           0.55        99\n",
      "   macro avg       0.73      0.62      0.52        99\n",
      "weighted avg       0.79      0.55      0.49        99\n",
      "\n",
      "\n",
      "\n",
      "Merck\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2243\n",
      "           1       1.00      0.07      0.13       152\n",
      "\n",
      "    accuracy                           0.94      2395\n",
      "   macro avg       0.97      0.54      0.55      2395\n",
      "weighted avg       0.94      0.94      0.92      2395\n",
      "\n",
      "\n",
      "\n",
      "BristolMyersSquibb\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1112\n",
      "           1       0.80      0.06      0.11        66\n",
      "\n",
      "    accuracy                           0.95      1178\n",
      "   macro avg       0.87      0.53      0.54      1178\n",
      "weighted avg       0.94      0.95      0.92      1178\n",
      "\n",
      "\n",
      "\n",
      "johnsonandjohnson\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1855\n",
      "           1       0.85      0.15      0.25        75\n",
      "\n",
      "    accuracy                           0.97      1930\n",
      "   macro avg       0.91      0.57      0.62      1930\n",
      "weighted avg       0.96      0.97      0.95      1930\n",
      "\n",
      "\n",
      "\n",
      "Abbott\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      1915\n",
      "           1       1.00      0.07      0.12       123\n",
      "\n",
      "    accuracy                           0.94      2038\n",
      "   macro avg       0.97      0.53      0.55      2038\n",
      "weighted avg       0.95      0.94      0.92      2038\n",
      "\n",
      "\n",
      "\n",
      "Boeing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      1018\n",
      "           1       0.88      0.06      0.11       124\n",
      "\n",
      "    accuracy                           0.90      1142\n",
      "   macro avg       0.89      0.53      0.53      1142\n",
      "weighted avg       0.89      0.90      0.85      1142\n",
      "\n",
      "\n",
      "\n",
      "UPS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.94        68\n",
      "           1       0.92      0.61      0.73        18\n",
      "\n",
      "    accuracy                           0.91        86\n",
      "   macro avg       0.91      0.80      0.84        86\n",
      "weighted avg       0.91      0.91      0.90        86\n",
      "\n",
      "\n",
      "\n",
      "3M\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      2993\n",
      "           1       1.00      0.03      0.05       215\n",
      "\n",
      "    accuracy                           0.93      3208\n",
      "   macro avg       0.97      0.51      0.51      3208\n",
      "weighted avg       0.94      0.93      0.91      3208\n",
      "\n",
      "\n",
      "\n",
      "Walmart\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       526\n",
      "           1       1.00      0.08      0.15        37\n",
      "\n",
      "    accuracy                           0.94       563\n",
      "   macro avg       0.97      0.54      0.56       563\n",
      "weighted avg       0.94      0.94      0.91       563\n",
      "\n",
      "\n",
      "\n",
      "Tesla\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89      1097\n",
      "           1       1.00      0.01      0.03       270\n",
      "\n",
      "    accuracy                           0.81      1367\n",
      "   macro avg       0.90      0.51      0.46      1367\n",
      "weighted avg       0.84      0.81      0.72      1367\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train on rest data and fit on comp data \n",
    "crLR_reports = []\n",
    "\n",
    "for comp in comp_list:\n",
    "    train = pd.read_csv('balanced_data/' + comp + \"_rest_balanced_data_train.csv\", index_col = 0)\n",
    "    test = pd.read_csv('balanced_data/' + comp + \"_rest_balanced_data_test.csv\", index_col = 0)\n",
    "    \n",
    "    X_train = train['sentences']\n",
    "    X_test = test['sentences']\n",
    "\n",
    "    y_train = train['class']\n",
    "    y_test = test['class']\n",
    "    \n",
    "    comp_X_test = pd.read_csv('balanced_data/' + comp + \"_comp_balanced_data.csv\")['sentences']\n",
    "    comp_Y_test = pd.read_csv('balanced_data/' + comp + \"_comp_balanced_data.csv\")['class']\n",
    "    \n",
    "    \n",
    "    vectorizer_tfidf = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "\n",
    "    train_tfIdf = vectorizer_tfidf.fit_transform(X_train.values.astype('U'))\n",
    "\n",
    "    # testing on balanced comp sentences \n",
    "    test_tfIdf_comp = vectorizer_tfidf.transform(comp_X_test.values.astype('U'))\n",
    "    \n",
    "    # testing on all comp sentences\n",
    "    comp_all_X_test = pd.read_csv('balanced_data/' + comp + \"_comp_all_data.csv\")['sentences']\n",
    "    comp_all_Y_test = pd.read_csv('balanced_data/' + comp + \"_comp_all_data.csv\")['class']\n",
    "    comp_key = pd.read_csv('balanced_data/' + comp + \"_comp_all_data.csv\")['key']\n",
    "    \n",
    "    test_all_tfIdf_comp = vectorizer_tfidf.transform(comp_all_X_test.values.astype('U'))\n",
    "    \n",
    "    # logistic regression prediction and evaluation\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    \n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(train_tfIdf, y_train)\n",
    "    predLR =  lr.predict(test_all_tfIdf_comp)\n",
    "\n",
    "#     nb_classifier = MultinomialNB()\n",
    "#     nb_classifier.fit(train_tfIdf, y_train)\n",
    "#     predLR = nb_classifier.predict(test_all_tfIdf_comp) \n",
    "\n",
    "    crLR = classification_report(predLR, comp_all_Y_test)\n",
    "    print(comp)\n",
    "    print(crLR)\n",
    "    print(\"\\n\")\n",
    "    crLR = classification_report(predLR, comp_all_Y_test, output_dict=True)\n",
    "    \n",
    "    # update the classification report as it's printed\n",
    "    crLR.update({\"accuracy\": {\"precision\": None, \"recall\": None, \"f1-score\": crLR[\"accuracy\"], \"support\": crLR['macro avg']['support']}})\n",
    "    df = pd.DataFrame(crLR).transpose()\n",
    "    df.index.name = comp\n",
    "    crLR_reports.append(df)\n",
    "    \n",
    "    df = pd.DataFrame([comp_key.to_list(), comp_all_X_test.to_list(), comp_all_Y_test.to_list(), list(predLR)]).transpose()\n",
    "    df = df.rename(columns = { 0: 'key', 1: 'sentences', 2: 'class', 3: 'predicted'})\n",
    "    df.to_csv('test_sentences_' + comp + '.csv', encoding = 'utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cfc40e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_3M = pd.read_csv('test_sentences_3M.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "69b1b03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentences\n",
       "class           \n",
       "0           3202\n",
       "1              6"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_3M.groupby('class').count()[['sentences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "57e4f238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentences\n",
       "predicted           \n",
       "0               2993\n",
       "1                215"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_3M.groupby('predicted').count()[['sentences']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ad687f",
   "metadata": {},
   "source": [
    "### Printing the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0d54fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(crLR_reports, keys=map(lambda d: d.index.name, crLR_reports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8145bc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.names = [None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bca7c58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f4daad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.support = df.support.apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d9b0b3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">EliLilly</th>\n",
       "      <th>0</th>\n",
       "      <td>0.46</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.40</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.55</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.52</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.49</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Merck</th>\n",
       "      <th>0</th>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.13</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">BristolMyersSquibb</th>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">johnsonandjohnson</th>\n",
       "      <th>0</th>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Abbott</th>\n",
       "      <th>0</th>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Boeing</th>\n",
       "      <th>0</th>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">UPS</th>\n",
       "      <th>0</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.73</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.91</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.84</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3M</th>\n",
       "      <th>0</th>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>3208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>3208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Walmart</th>\n",
       "      <th>0</th>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.15</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Tesla</th>\n",
       "      <th>0</th>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 precision  recall  f1-score  support\n",
       "EliLilly           0                  0.46    1.00      0.63       39\n",
       "                   1                  1.00    0.25      0.40       60\n",
       "                   accuracy            NaN     NaN      0.55       99\n",
       "                   macro avg          0.73    0.62      0.52       99\n",
       "                   weighted avg       0.79    0.55      0.49       99\n",
       "Merck              0                  0.94    1.00      0.97     2243\n",
       "                   1                  1.00    0.07      0.13      152\n",
       "                   accuracy            NaN     NaN      0.94     2395\n",
       "                   macro avg          0.97    0.54      0.55     2395\n",
       "                   weighted avg       0.94    0.94      0.92     2395\n",
       "BristolMyersSquibb 0                  0.95    1.00      0.97     1112\n",
       "                   1                  0.80    0.06      0.11       66\n",
       "                   accuracy            NaN     NaN      0.95     1178\n",
       "                   macro avg          0.87    0.53      0.54     1178\n",
       "                   weighted avg       0.94    0.95      0.92     1178\n",
       "johnsonandjohnson  0                  0.97    1.00      0.98     1855\n",
       "                   1                  0.85    0.15      0.25       75\n",
       "                   accuracy            NaN     NaN      0.97     1930\n",
       "                   macro avg          0.91    0.57      0.62     1930\n",
       "                   weighted avg       0.96    0.97      0.95     1930\n",
       "Abbott             0                  0.94    1.00      0.97     1915\n",
       "                   1                  1.00    0.07      0.12      123\n",
       "                   accuracy            NaN     NaN      0.94     2038\n",
       "                   macro avg          0.97    0.53      0.55     2038\n",
       "                   weighted avg       0.95    0.94      0.92     2038\n",
       "Boeing             0                  0.90    1.00      0.95     1018\n",
       "                   1                  0.88    0.06      0.11      124\n",
       "                   accuracy            NaN     NaN      0.90     1142\n",
       "                   macro avg          0.89    0.53      0.53     1142\n",
       "                   weighted avg       0.89    0.90      0.85     1142\n",
       "UPS                0                  0.91    0.99      0.94       68\n",
       "                   1                  0.92    0.61      0.73       18\n",
       "                   accuracy            NaN     NaN      0.91       86\n",
       "                   macro avg          0.91    0.80      0.84       86\n",
       "                   weighted avg       0.91    0.91      0.90       86\n",
       "3M                 0                  0.93    1.00      0.97     2993\n",
       "                   1                  1.00    0.03      0.05      215\n",
       "                   accuracy            NaN     NaN      0.93     3208\n",
       "                   macro avg          0.97    0.51      0.51     3208\n",
       "                   weighted avg       0.94    0.93      0.91     3208\n",
       "Walmart            0                  0.94    1.00      0.97      526\n",
       "                   1                  1.00    0.08      0.15       37\n",
       "                   accuracy            NaN     NaN      0.94      563\n",
       "                   macro avg          0.97    0.54      0.56      563\n",
       "                   weighted avg       0.94    0.94      0.91      563\n",
       "Tesla              0                  0.80    1.00      0.89     1097\n",
       "                   1                  1.00    0.01      0.03      270\n",
       "                   accuracy            NaN     NaN      0.81     1367\n",
       "                   macro avg          0.90    0.51      0.46     1367\n",
       "                   weighted avg       0.84    0.81      0.72     1367"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "538e2e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"summarizer_test_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a568f55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "db1c1e886ca7e5218f158543d1b9804c0a5c522f5654be9e23cd8543b350db84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
