{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "329b5117",
   "metadata": {},
   "source": [
    "### List of Companies to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ce9861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xml.sax.handler import feature_namespace_prefixes\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1669b135",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_list = [\"EliLilly\", \"Merck\", \"BristolMyersSquibb\", \"johnsonandjohnson\", \"Abbott\", \"Boeing\",\n",
    "             \"UPS\", \"3M\", \"Walmart\", \"Tesla\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134b712e",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc16f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tylerryoo/t3/summarizer_test_result/test_all_sentences'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ca110dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = pd.read_csv(\"../../extracted_sentences/notebooks/final_extracted_statistics_notebooks/all_sentences.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e74e0153",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = all_sentences[all_sentences.label == 'rel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "417aedff",
   "metadata": {},
   "outputs": [],
   "source": [
    "irr = all_sentences[all_sentences.label == 'irr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7367da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevant = irr\n",
    "relevant = rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdea939a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_irrelevant: 77258\n",
      "total_relevant: 853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c8/4mvtm2vs4_vdgzz_n030prfm0000gn/T/ipykernel_83599/3000358227.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  irrelevant[\"class\"] = 0\n",
      "/var/folders/c8/4mvtm2vs4_vdgzz_n030prfm0000gn/T/ipykernel_83599/3000358227.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  relevant[\"class\"] = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>company_label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>Here’s how that  helped the planet: Avoided 2....</td>\n",
       "      <td>HomeDepot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>These data include the commissioning of two co...</td>\n",
       "      <td>Total</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>From 2010 to  2013, TotalEnergies developed a ...</td>\n",
       "      <td>Total</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>305-1 Direct greenhouse gas (GHG) emissions (S...</td>\n",
       "      <td>Linde</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>Nearly half of our carbon  intensity improveme...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentences company_label  class\n",
       "438  Here’s how that  helped the planet: Avoided 2....     HomeDepot      1\n",
       "217  These data include the commissioning of two co...         Total      1\n",
       "230  From 2010 to  2013, TotalEnergies developed a ...         Total      1\n",
       "734  305-1 Direct greenhouse gas (GHG) emissions (S...         Linde      1\n",
       "471  Nearly half of our carbon  intensity improveme...        Amazon      1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull in the csv data\n",
    "# irrelevant = pd.read_csv(\"../../relevant_irrelevant_sentences_labeled/extracted_irrelevant_sentences.csv\")\n",
    "# relevant = pd.read_csv(\"../../relevant_irrelevant_sentences_labeled/extracted_relevant_sentences.csv\")\n",
    "irrelevant = irr\n",
    "relevant = rel\n",
    "\n",
    "print(\"total_irrelevant:\", len(irrelevant))\n",
    "print(\"total_relevant:\", len(relevant))\n",
    "irrelevant[\"class\"] = 0\n",
    "relevant[\"class\"] = 1\n",
    "\n",
    "irrelevant = irrelevant[['sentences', 'company_label', 'class']]\n",
    "relevant = relevant[['sentences', 'company_label', 'class']]\n",
    "relevant.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40b4df3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EliLilly \n",
      " 84 15 77174 838\n",
      "Merck \n",
      " 2403 10 74855 843\n",
      "BristolMyersSquibb \n",
      " 1183 5 76075 848\n",
      "johnsonandjohnson \n",
      " 1937 12 75321 841\n",
      "Abbott \n",
      " 2073 7 75185 846\n",
      "Boeing \n",
      " 1147 8 76111 845\n",
      "UPS \n",
      " 76 10 77182 843\n",
      "3M \n",
      " 3246 5 74012 848\n",
      "Walmart \n",
      " 571 3 76687 850\n",
      "Tesla \n",
      " 1378 4 75880 849\n"
     ]
    }
   ],
   "source": [
    "for comp_name in comp_list:\n",
    "    comp_irrelevant = irrelevant[irrelevant['company_label'] == comp_name]\n",
    "    comp_relevant = relevant[relevant['company_label'] == comp_name]\n",
    "    comp_all = pd.concat([comp_relevant,comp_irrelevant])\n",
    "    \n",
    "    comp_all.to_csv(comp_name + '_comp_all_data.csv', encoding = 'utf-8-sig')\n",
    "    \n",
    "    rest_irrelevant = irrelevant[irrelevant['company_label'] != comp_name]\n",
    "    rest_relevant = relevant[relevant['company_label'] != comp_name]\n",
    "    \n",
    "    print(comp_name, \"\\n\", len(comp_irrelevant), len(comp_relevant),len(rest_irrelevant), len(rest_relevant))\n",
    "    \n",
    "    comp_sample_irr = comp_irrelevant.sample(n = len(comp_relevant), random_state = 1)\n",
    "    rest_sample_irr = rest_irrelevant.sample(n = len(rest_relevant), random_state = 1)\n",
    "    \n",
    "    comp_balanced_set = pd.concat([comp_relevant, comp_sample_irr], ignore_index = True)\n",
    "    rest_balanced_set = pd.concat([rest_relevant, rest_sample_irr], ignore_index = True)\n",
    "    \n",
    "    # Train Test Split on comp_balanced_set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(comp_balanced_set['sentences'], \n",
    "                                                        comp_balanced_set['class'], test_size=0.1, random_state=100)\n",
    "\n",
    "    dfbalanced = pd.concat([comp_balanced_set], ignore_index=True)\n",
    "    dfbalanced.to_csv(comp_name + '_comp_balanced_data.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "    dfbalanced_train = pd.concat([X_train.to_frame(), y_train.to_frame()], axis = 1, ignore_index = True)\n",
    "    dfbalanced_train.columns = ['sentences', 'class']\n",
    "    dfbalanced_train.to_csv(comp_name + '_comp_balanced_data_train.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "    dfbalanced_test = pd.concat([X_test.to_frame(), y_test.to_frame()], axis = 1, ignore_index = True)\n",
    "    dfbalanced_test.columns = ['sentences', 'class']\n",
    "    dfbalanced_test.to_csv(comp_name + '_comp_balanced_data_test.csv', encoding = 'utf-8-sig')\n",
    "    \n",
    "    # Train Test Split on rest_balanced_set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(rest_balanced_set['sentences'], \n",
    "                                                        rest_balanced_set['class'], test_size=0.1, random_state=100)\n",
    "\n",
    "    dfbalanced = pd.concat([rest_balanced_set], ignore_index=True)\n",
    "    dfbalanced.to_csv(comp_name + '_rest_balanced_data.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "    dfbalanced_train = pd.concat([X_train.to_frame(), y_train.to_frame()], axis = 1, ignore_index = True)\n",
    "    dfbalanced_train.columns = ['sentences', 'class']\n",
    "    dfbalanced_train.to_csv(comp_name + '_rest_balanced_data_train.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "    dfbalanced_test = pd.concat([X_test.to_frame(), y_test.to_frame()], axis = 1, ignore_index = True)\n",
    "    dfbalanced_test.columns = ['sentences', 'class']\n",
    "    dfbalanced_test.to_csv(comp_name + '_rest_balanced_data_test.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c1dd1a",
   "metadata": {},
   "source": [
    "### Logistics Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70587332",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_list = [\"EliLilly\", \"Merck\", \"BristolMyersSquibb\", \"johnsonandjohnson\", \"Abbott\", \"Boeing\",\n",
    "             \"UPS\", \"3M\", \"Walmart\", \"Tesla\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "196f679e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentences</th>\n",
       "      <th>company_label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>These projects will address approximately 35 p...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>These agreements follow a 2018 U.S.   wind VPP...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Vehicle fleet Approximately nine percent of ou...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>• 40 percent of our U.S. fleet are now partial...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>• Over 50 percent of the vehicles being utiliz...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>1671</td>\n",
       "      <td>The data in this table excludes ONE Brands,  L...</td>\n",
       "      <td>Hershey</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>1672</td>\n",
       "      <td>It is a value that matters deeply to  3M emplo...</td>\n",
       "      <td>3M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>1673</td>\n",
       "      <td>The PSI assessment process involved detailed r...</td>\n",
       "      <td>Dominion_Energy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>1674</td>\n",
       "      <td>Once  onboarded, our new colleagues are  suppo...</td>\n",
       "      <td>ThermoFisherScientifiic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>1675</td>\n",
       "      <td>Pillar 4   Influencing climate action in   our...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1676 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                          sentences  \\\n",
       "0              0  These projects will address approximately 35 p...   \n",
       "1              1  These agreements follow a 2018 U.S.   wind VPP...   \n",
       "2              2  Vehicle fleet Approximately nine percent of ou...   \n",
       "3              3  • 40 percent of our U.S. fleet are now partial...   \n",
       "4              4  • Over 50 percent of the vehicles being utiliz...   \n",
       "...          ...                                                ...   \n",
       "1671        1671  The data in this table excludes ONE Brands,  L...   \n",
       "1672        1672  It is a value that matters deeply to  3M emplo...   \n",
       "1673        1673  The PSI assessment process involved detailed r...   \n",
       "1674        1674  Once  onboarded, our new colleagues are  suppo...   \n",
       "1675        1675  Pillar 4   Influencing climate action in   our...   \n",
       "\n",
       "                company_label  class  \n",
       "0                       Merck      1  \n",
       "1                       Merck      1  \n",
       "2                       Merck      1  \n",
       "3                       Merck      1  \n",
       "4                       Merck      1  \n",
       "...                       ...    ...  \n",
       "1671                  Hershey      0  \n",
       "1672                       3M      0  \n",
       "1673          Dominion_Energy      0  \n",
       "1674  ThermoFisherScientifiic      0  \n",
       "1675                Accenture      0  \n",
       "\n",
       "[1676 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('EliLilly_rest_balanced_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bb1113d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EliLilly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65        40\n",
      "           1       1.00      0.25      0.41        59\n",
      "\n",
      "    accuracy                           0.56        99\n",
      "   macro avg       0.74      0.63      0.53        99\n",
      "weighted avg       0.79      0.56      0.50        99\n",
      "\n",
      "\n",
      "\n",
      "Merck\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2248\n",
      "           1       1.00      0.06      0.11       165\n",
      "\n",
      "    accuracy                           0.94      2413\n",
      "   macro avg       0.97      0.53      0.54      2413\n",
      "weighted avg       0.94      0.94      0.91      2413\n",
      "\n",
      "\n",
      "\n",
      "BristolMyersSquibb\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1122\n",
      "           1       0.80      0.06      0.11        66\n",
      "\n",
      "    accuracy                           0.95      1188\n",
      "   macro avg       0.87      0.53      0.54      1188\n",
      "weighted avg       0.94      0.95      0.92      1188\n",
      "\n",
      "\n",
      "\n",
      "johnsonandjohnson\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1862\n",
      "           1       0.92      0.13      0.22        87\n",
      "\n",
      "    accuracy                           0.96      1949\n",
      "   macro avg       0.94      0.56      0.60      1949\n",
      "weighted avg       0.96      0.96      0.95      1949\n",
      "\n",
      "\n",
      "\n",
      "Abbott\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      1951\n",
      "           1       1.00      0.05      0.10       129\n",
      "\n",
      "    accuracy                           0.94      2080\n",
      "   macro avg       0.97      0.53      0.54      2080\n",
      "weighted avg       0.94      0.94      0.92      2080\n",
      "\n",
      "\n",
      "\n",
      "Boeing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      1038\n",
      "           1       0.88      0.06      0.11       117\n",
      "\n",
      "    accuracy                           0.90      1155\n",
      "   macro avg       0.89      0.53      0.53      1155\n",
      "weighted avg       0.90      0.90      0.86      1155\n",
      "\n",
      "\n",
      "\n",
      "UPS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94        67\n",
      "           1       1.00      0.53      0.69        19\n",
      "\n",
      "    accuracy                           0.90        86\n",
      "   macro avg       0.94      0.76      0.81        86\n",
      "weighted avg       0.91      0.90      0.88        86\n",
      "\n",
      "\n",
      "\n",
      "3M\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      3049\n",
      "           1       1.00      0.02      0.05       202\n",
      "\n",
      "    accuracy                           0.94      3251\n",
      "   macro avg       0.97      0.51      0.51      3251\n",
      "weighted avg       0.94      0.94      0.91      3251\n",
      "\n",
      "\n",
      "\n",
      "Walmart\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       536\n",
      "           1       1.00      0.08      0.15        38\n",
      "\n",
      "    accuracy                           0.94       574\n",
      "   macro avg       0.97      0.54      0.56       574\n",
      "weighted avg       0.94      0.94      0.91       574\n",
      "\n",
      "\n",
      "\n",
      "Tesla\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90      1129\n",
      "           1       1.00      0.02      0.03       253\n",
      "\n",
      "    accuracy                           0.82      1382\n",
      "   macro avg       0.91      0.51      0.47      1382\n",
      "weighted avg       0.85      0.82      0.74      1382\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train on rest data and fit on comp data \n",
    "crLR_reports = []\n",
    "\n",
    "for comp in comp_list: \n",
    "    train = pd.read_csv(comp + \"_rest_balanced_data_train.csv\")\n",
    "    test = pd.read_csv(comp + \"_rest_balanced_data_test.csv\")\n",
    "    \n",
    "    train.drop(columns = ['Unnamed: 0'])\n",
    "    test.drop(columns = ['Unnamed: 0'])\n",
    "    \n",
    "    X_train = train['sentences']\n",
    "    X_test = test['sentences']\n",
    "\n",
    "    y_train = train['class']\n",
    "    y_test = test['class']\n",
    "    \n",
    "    comp_X_test = pd.read_csv(comp + \"_comp_balanced_data.csv\")['sentences']\n",
    "    comp_Y_test = pd.read_csv(comp + \"_comp_balanced_data.csv\")['class']\n",
    "    \n",
    "    \n",
    "    vectorizer_tfidf = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "\n",
    "    train_tfIdf = vectorizer_tfidf.fit_transform(X_train.values.astype('U'))\n",
    "\n",
    "    # testing on balanced comp sentences \n",
    "    test_tfIdf_comp = vectorizer_tfidf.transform(comp_X_test.values.astype('U'))\n",
    "    \n",
    "    # testing on all comp sentences\n",
    "    comp_all_X_test = pd.read_csv(comp + \"_comp_all_data.csv\")['sentences']\n",
    "    comp_all_Y_test = pd.read_csv(comp + \"_comp_all_data.csv\")['class']\n",
    "    test_all_tfIdf_comp = vectorizer_tfidf.transform(comp_all_X_test.values.astype('U'))\n",
    "    \n",
    "    # logistic regression prediction and evaluation\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(train_tfIdf, y_train)\n",
    "\n",
    "\n",
    "    predLR =  lr.predict(test_all_tfIdf_comp)\n",
    "\n",
    "    crLR = classification_report(predLR, comp_all_Y_test)\n",
    "    print(comp)\n",
    "    print(crLR)\n",
    "    print(\"\\n\")\n",
    "    crLR = classification_report(predLR, comp_all_Y_test, output_dict=True)\n",
    "    \n",
    "    df = pd.DataFrame(crLR).transpose()\n",
    "    df.index.name = comp\n",
    "    crLR_reports.append(df)\n",
    "    \n",
    "    df = pd.DataFrame([comp_all_X_test.to_list(), comp_all_Y_test.to_list(), list(predLR)]).transpose()\n",
    "    df = df.rename(columns = { 0: 'sentences', 1: 'class', 2: 'predicted'})\n",
    "    df.to_csv('test_sentences_' + comp + '.csv', encoding = 'utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ad687f",
   "metadata": {},
   "source": [
    "### Printing the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d54fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(crLR_reports, keys=map(lambda d: d.index.name, crLR_reports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8145bc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.names = [None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bca7c58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4daad89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">EliLilly</th>\n",
       "      <th>0</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.64</td>\n",
       "      <td>41.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.38</td>\n",
       "      <td>58.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.51</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.49</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Merck</th>\n",
       "      <th>0</th>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2288.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>160.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>2448.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2448.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">BristolMyersSquibb</th>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1128.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>61.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1189.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1189.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">johnsonandjohnson</th>\n",
       "      <th>0</th>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1999.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.27</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>2069.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2069.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Abbott</th>\n",
       "      <th>0</th>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2005.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>126.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2131.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2131.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Boeing</th>\n",
       "      <th>0</th>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1041.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>124.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1165.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1165.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">UPS</th>\n",
       "      <th>0</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.94</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.67</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.80</td>\n",
       "      <td>86.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>86.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3M</th>\n",
       "      <th>0</th>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>3086.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>194.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3280.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3280.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Walmart</th>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>560.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.18</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.58</td>\n",
       "      <td>591.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>591.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Tesla</th>\n",
       "      <th>0</th>\n",
       "      <td>0.82</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1147.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>252.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1399.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1399.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 precision  recall  f1-score  support\n",
       "EliLilly           0                  0.48    0.98      0.64    41.00\n",
       "                   1                  0.93    0.24      0.38    58.00\n",
       "                   accuracy           0.55    0.55      0.55     0.55\n",
       "                   macro avg          0.70    0.61      0.51    99.00\n",
       "                   weighted avg       0.74    0.55      0.49    99.00\n",
       "Merck              0                  0.94    1.00      0.97  2288.00\n",
       "                   1                  0.91    0.06      0.12   160.00\n",
       "                   accuracy           0.94    0.94      0.94     0.94\n",
       "                   macro avg          0.92    0.53      0.54  2448.00\n",
       "                   weighted avg       0.94    0.94      0.91  2448.00\n",
       "BristolMyersSquibb 0                  0.95    1.00      0.97  1128.00\n",
       "                   1                  0.50    0.03      0.06    61.00\n",
       "                   accuracy           0.95    0.95      0.95     0.95\n",
       "                   macro avg          0.73    0.52      0.52  1189.00\n",
       "                   weighted avg       0.93    0.95      0.93  1189.00\n",
       "johnsonandjohnson  0                  0.97    1.00      0.98  1999.00\n",
       "                   1                  0.85    0.16      0.27    70.00\n",
       "                   accuracy           0.97    0.97      0.97     0.97\n",
       "                   macro avg          0.91    0.58      0.63  2069.00\n",
       "                   weighted avg       0.97    0.97      0.96  2069.00\n",
       "Abbott             0                  0.94    1.00      0.97  2005.00\n",
       "                   1                  1.00    0.06      0.12   126.00\n",
       "                   accuracy           0.94    0.94      0.94     0.94\n",
       "                   macro avg          0.97    0.53      0.55  2131.00\n",
       "                   weighted avg       0.95    0.94      0.92  2131.00\n",
       "Boeing             0                  0.90    1.00      0.95  1041.00\n",
       "                   1                  0.86    0.05      0.09   124.00\n",
       "                   accuracy           0.90    0.90      0.90     0.90\n",
       "                   macro avg          0.88    0.52      0.52  1165.00\n",
       "                   weighted avg       0.89    0.90      0.85  1165.00\n",
       "UPS                0                  0.91    0.97      0.94    70.00\n",
       "                   1                  0.82    0.56      0.67    16.00\n",
       "                   accuracy           0.90    0.90      0.90     0.90\n",
       "                   macro avg          0.86    0.77      0.80    86.00\n",
       "                   weighted avg       0.89    0.90      0.89    86.00\n",
       "3M                 0                  0.94    1.00      0.97  3086.00\n",
       "                   1                  1.00    0.04      0.08   194.00\n",
       "                   accuracy           0.94    0.94      0.94     0.94\n",
       "                   macro avg          0.97    0.52      0.52  3280.00\n",
       "                   weighted avg       0.95    0.94      0.92  3280.00\n",
       "Walmart            0                  0.95    1.00      0.98   560.00\n",
       "                   1                  1.00    0.10      0.18    31.00\n",
       "                   accuracy           0.95    0.95      0.95     0.95\n",
       "                   macro avg          0.98    0.55      0.58   591.00\n",
       "                   weighted avg       0.95    0.95      0.93   591.00\n",
       "Tesla              0                  0.82    1.00      0.90  1147.00\n",
       "                   1                  1.00    0.01      0.02   252.00\n",
       "                   accuracy           0.82    0.82      0.82     0.82\n",
       "                   macro avg          0.91    0.51      0.46  1399.00\n",
       "                   weighted avg       0.85    0.82      0.74  1399.00"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "538e2e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"summarizer_test_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432454cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "db1c1e886ca7e5218f158543d1b9804c0a5c522f5654be9e23cd8543b350db84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
