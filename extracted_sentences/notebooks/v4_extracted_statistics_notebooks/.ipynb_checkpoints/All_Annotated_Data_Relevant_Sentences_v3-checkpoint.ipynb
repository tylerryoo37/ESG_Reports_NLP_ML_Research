{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Read Data Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-1) Pulling in All the Data Across Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "from nltk import tokenize\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r HC_reltext\n",
    "%store -r HC_alltext\n",
    "%store -r HC_stat\n",
    "\n",
    "%store -r IND_reltext\n",
    "%store -r IND_alltext\n",
    "%store -r IND_stat\n",
    "\n",
    "%store -r Energy_reltext\n",
    "%store -r Energy_alltext\n",
    "%store -r Energy_stat\n",
    "\n",
    "%store -r CONSTA_reltext\n",
    "%store -r CONSTA_alltext\n",
    "%store -r CONSTA_stat\n",
    "\n",
    "%store -r CONDIS_reltext\n",
    "%store -r CONDIS_alltext\n",
    "%store -r CONDIS_stat\n",
    "\n",
    "%store -r IT_reltext\n",
    "%store -r IT_alltext\n",
    "%store -r IT_stat\n",
    "\n",
    "%store -r Real_Estate_reltext\n",
    "%store -r Real_Estate_alltext\n",
    "%store -r Real_Estate_stat\n",
    "\n",
    "%store -r Materials_reltext\n",
    "%store -r Materials_alltext\n",
    "%store -r Materials_stat\n",
    "\n",
    "%store -r Utilities_reltext\n",
    "%store -r Utilities_alltext\n",
    "%store -r Utilities_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read  <ins>total_relevant</ins>, <ins>total_all</ins>, (both relevant and irrelevant),  <ins>total_stat</ins> (statistics of relevant and all sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_relevant = pd.concat([HC_reltext, IND_reltext, Energy_reltext,\n",
    "                 CONSTA_reltext, CONDIS_reltext, IT_reltext,\n",
    "                 Real_Estate_reltext, Materials_reltext, Utilities_reltext])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_all = pd.concat([HC_alltext, IND_alltext, Energy_alltext,\n",
    "                 CONSTA_alltext, CONDIS_alltext, IT_alltext,\n",
    "                 Real_Estate_alltext, Materials_alltext, Utilities_alltext])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <ins>Regenerate total_stat </ins>after removing duplicate sentences and separating relevant and irreleavant sentences from all sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_stat  = pd.concat([HC_stat, IND_stat, Energy_stat,\n",
    "#               CONSTA_stat, CONDIS_stat, IT_stat,\n",
    "#               Real_Estate_stat, Materials_stat, Utilities_stat])\n",
    "\n",
    "# total_stat['percentages'] = round(total_stat['percentages'],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-2) Drop Duplicated Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevant_sentences: 1000 -> 998\n"
     ]
    }
   ],
   "source": [
    "original_relevant = len(total_relevant)\n",
    "len(total_relevant.drop_duplicates())\n",
    "total_relevant = total_relevant.drop_duplicates()\n",
    "print(\"relevant_sentences:\", original_relevant, \"->\", len(total_relevant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_sentences: 81912 -> 79781\n"
     ]
    }
   ],
   "source": [
    "original_all = len(total_all)\n",
    "len(total_all.drop_duplicates())\n",
    "total_all = total_all.drop_duplicates()\n",
    "print(\"all_sentences:\", original_all, \"->\", len(total_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Extracting Irrelevant Sentences from All Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This method below doesn't correctly extract irrelevant sentences. Another method is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_test = []\n",
    "for i in total_relevant['relevant_sentences'].to_list():\n",
    "    if i in total_all['all_sentences'].to_list():\n",
    "        rel_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This method to extract relevant sentences:  67 vs. original_relevant_sentences:  998\n"
     ]
    }
   ],
   "source": [
    "print(\"This method to extract relevant sentences: \", len(rel_test), \"vs.\", \"original_relevant_sentences: \", len(total_relevant['relevant_sentences'].to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing fuzz package to compare strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install fuzzywuzzy\n",
    "# pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.partial_ratio('In 2021, we reduced our energy consumption by 2.9%,', \n",
    "                   'In 2021, we reduced our energy consumption by 2.9%, and we reduced our absolute GHG emissions by 9% compared to 2020.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B-1) Eliminating short sentences from relevant and all sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the number of letters of sentences to make sure sentences that have less than 5 letters are eliminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50])"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique([len(i.split(\" \")) for i in total_relevant['relevant_sentences']])[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50])"
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([len(i.split(\" \")) for i in total_all['all_sentences']])[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_relevant['sent_count'] = total_relevant['relevant_sentences'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_all['sent_count'] = total_all['all_sentences'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_relevant = total_relevant[total_relevant['sent_count'] >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_all = total_all[total_all['sent_count'] >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevant_sentences: 1000 -> 957\n",
      "all_sentences: 81912 -> 78112\n"
     ]
    }
   ],
   "source": [
    "# Check the length of new sentences after dropping duplicates\n",
    "\n",
    "print(\"relevant_sentences:\", original_relevant, \"->\", len(total_relevant))\n",
    "print(\"all_sentences:\", original_all, \"->\", len(total_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the sentences into lists for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_var = total_relevant['relevant_sentences'].to_list()\n",
    "rel_lab = total_relevant['company_label'].to_list()\n",
    "all_var = total_all['all_sentences'].to_list()\n",
    "all_lab = total_all['company_label'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### =============================== PAUSE RUNNING HERE ===================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B-2) Conduct string matching to separate relevant and irrelevant sentences from all sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # string comparison to separate relevant and irrelevant sentences from all sentences\n",
    "# matrel = []\n",
    "# matlabel = []\n",
    "# orgrel = []\n",
    "# track = 0\n",
    "# for i, j in zip(rel_var, rel_lab):\n",
    "#     # extract relevant sentences from all\n",
    "#     val = process.extractOne(i, all_var, scorer = fuzz.partial_ratio, score_cutoff = 90)\n",
    "#     matrel.append(val)\n",
    "#     matlabel.append(j)\n",
    "#     orgrel.append(i)\n",
    "#     print(track, end = \" \")\n",
    "#     print(val)\n",
    "#     track +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the outcome of string matched sentences and save the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string_matched_old = pd.DataFrame([matrel, orgrel, matlabel], index = ['matched_rel', 'original_rel', 'company_label']).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string_matched = pd.DataFrame([matrel, orgrel, matlabel], index = ['matched_rel', 'original_rel', 'company_label']).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string_matched.iloc[156]['original_rel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extracting sentences portion from the tuple with (sentence, ratio) format\n",
    "# string_matched['matched_rel_only'] = [i[0] if i is not None else '' for i in string_matched.matched_rel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string_matched.to_csv(\"string_matched.csv\", encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### =============================== RESUME RUNNING HERE ===================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep track of sentences that didn't get matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'string_matched.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [888]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m string_matched \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstring_matched.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:678\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    663\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    664\u001b[0m     dialect,\n\u001b[1;32m    665\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    675\u001b[0m )\n\u001b[1;32m    676\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:932\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1216\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'string_matched.csv'"
     ]
    }
   ],
   "source": [
    "string_matched = pd.read_csv('string_matched.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "still_not_matched = string_matched[string_matched.matched_rel.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "still_not_matched['sent_count'] = still_not_matched['original_rel'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [],
   "source": [
    "still_not_matched.to_csv('sentenences_not_matched.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep track of sentences that got matched (only use this version from now on: disregard sentences not matched and short sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_matched = string_matched[string_matched.matched_rel.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_matched = sentences_matched.drop_duplicates(subset = ['matched_rel_only', 'company_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_matched.to_csv('sentences_matched.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "854"
      ]
     },
     "execution_count": 893,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_matched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN FROM HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B-4) Separate relevant and irrelevant sentences: aligning matched sentences with total_all sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindexing sentences\n",
    "sentences_matched = pd.read_csv('sentences_matched.csv', index_col = 0)\n",
    "sentences_matched = sentences_matched.reset_index()\n",
    "sentences_matched = sentences_matched.drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_var_df = pd.DataFrame([all_var, all_lab], index = ['matched_rel_only', 'company_label']).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_matched = sentences_matched.merge(all_var_df, how = 'right', on = ['matched_rel_only', 'company_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_from_all = sentences_matched[sentences_matched.matched_rel.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "irr_from_all = sentences_matched[sentences_matched.matched_rel.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Sentences:  847 | Irrelevant Sentences:  77265 | Total:  78112\n"
     ]
    }
   ],
   "source": [
    "print(\"Relevant Sentences: \", len(rel_from_all), \"| Irrelevant Sentences: \", len(irr_from_all), \"| Total: \", len(rel_from_all) + len(irr_from_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_from_all = rel_from_all.rename(columns = {'original_rel': 'relevant_sentences'})\n",
    "irr_from_all = irr_from_all.rename(columns = {'matched_rel_only': 'irrelevant_sentences'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_from_all = rel_from_all[['relevant_sentences', 'company_label']]\n",
    "irr_from_all = irr_from_all[['irrelevant_sentences', 'company_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_from_all = rel_from_all.rename(columns = {'relevant_sentences': 'sentences'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_from_all['label'] = 'rel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [],
   "source": [
    "irr_from_all = irr_from_all.rename(columns = {'irrelevant_sentences': 'sentences'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "irr_from_all['label'] = 'irr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent = pd.concat([rel_from_all, irr_from_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78112"
      ]
     },
     "execution_count": 907,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up extra spaces in sentences to further remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent['sentences'] = all_sent['sentences'].apply(lambda x: re.sub(' +', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent['sentences'] = all_sent['sentences'].apply(lambda x: re.sub('\\xa0', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent['sentences'] = all_sent['sentences'].apply(lambda x: re.sub('\\t', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent['sentences'] = all_sent['sentences'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>company_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>• Achieve a 60% reduction in scope 1 and scope...</td>\n",
       "      <td>UnitedHealthGroup</td>\n",
       "      <td>irr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>This includes overseeing the company’s program...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>irr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>This agreement represents another landmark mil...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>irr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>The global stockpile will offer a critical, ra...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>irr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>Prescription Drug Marketing Act and all applic...</td>\n",
       "      <td>Merck</td>\n",
       "      <td>irr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75840</th>\n",
       "      <td>Then we will prioritize the categories for whi...</td>\n",
       "      <td>Duke_Energy</td>\n",
       "      <td>irr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75856</th>\n",
       "      <td>These releases are expected to decrease signif...</td>\n",
       "      <td>Duke_Energy</td>\n",
       "      <td>irr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75875</th>\n",
       "      <td>Building a safe, diverse and engaged workforce.</td>\n",
       "      <td>Duke_Energy</td>\n",
       "      <td>irr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75933</th>\n",
       "      <td>In December, 71% of enrollments in payment ass...</td>\n",
       "      <td>Duke_Energy</td>\n",
       "      <td>irr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76332</th>\n",
       "      <td>The most directly comparable GAAP measure for ...</td>\n",
       "      <td>Duke_Energy</td>\n",
       "      <td>irr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentences      company_label  \\\n",
       "609    • Achieve a 60% reduction in scope 1 and scope...  UnitedHealthGroup   \n",
       "1606   This includes overseeing the company’s program...              Merck   \n",
       "1855   This agreement represents another landmark mil...              Merck   \n",
       "1856   The global stockpile will offer a critical, ra...              Merck   \n",
       "2093   Prescription Drug Marketing Act and all applic...              Merck   \n",
       "...                                                  ...                ...   \n",
       "75840  Then we will prioritize the categories for whi...        Duke_Energy   \n",
       "75856  These releases are expected to decrease signif...        Duke_Energy   \n",
       "75875    Building a safe, diverse and engaged workforce.        Duke_Energy   \n",
       "75933  In December, 71% of enrollments in payment ass...        Duke_Energy   \n",
       "76332  The most directly comparable GAAP measure for ...        Duke_Energy   \n",
       "\n",
       "      label  \n",
       "609     irr  \n",
       "1606    irr  \n",
       "1855    irr  \n",
       "1856    irr  \n",
       "2093    irr  \n",
       "...     ...  \n",
       "75840   irr  \n",
       "75856   irr  \n",
       "75875   irr  \n",
       "75933   irr  \n",
       "76332   irr  \n",
       "\n",
       "[785 rows x 3 columns]"
      ]
     },
     "execution_count": 912,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sent[all_sent.duplicated(subset = 'sentences')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent['sent_no_space'] = all_sent.sentences.str.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent = all_sent.drop_duplicates(subset = 'sent_no_space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent = all_sent.drop_duplicates(subset = 'sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent = all_sent.drop('sent_no_space', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent.index = [x for x in range(1, len(all_sent)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent['key'] = all_sent.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent = all_sent.reindex(columns= ['key', 'sentences', 'company_label', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>sentences</th>\n",
       "      <th>company_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>In 2021, 9.6% of our purchased electricity cam...</td>\n",
       "      <td>EliLilly</td>\n",
       "      <td>rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A large portion of this renewable electricity ...</td>\n",
       "      <td>EliLilly</td>\n",
       "      <td>rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>From 2012 to 2020, we achieved a 26% reduction...</td>\n",
       "      <td>EliLilly</td>\n",
       "      <td>rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>In 2021, we achieved a 9% absolute emissions r...</td>\n",
       "      <td>EliLilly</td>\n",
       "      <td>rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>This reduction was partially driven by energy ...</td>\n",
       "      <td>EliLilly</td>\n",
       "      <td>rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77273</th>\n",
       "      <td>77273</td>\n",
       "      <td>→ FPL’s four nuclear units continue to operate...</td>\n",
       "      <td>NextEraEnergyZeroCarbonBlueprint</td>\n",
       "      <td>irr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77274</th>\n",
       "      <td>77274</td>\n",
       "      <td>Technology We assume that: → FPL’s gas plants ...</td>\n",
       "      <td>NextEraEnergyZeroCarbonBlueprint</td>\n",
       "      <td>irr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77275</th>\n",
       "      <td>77275</td>\n",
       "      <td>→ NextEra Energy Resources would invest in ele...</td>\n",
       "      <td>NextEraEnergyZeroCarbonBlueprint</td>\n",
       "      <td>irr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77276</th>\n",
       "      <td>77276</td>\n",
       "      <td>→ All non-FPL fossil generation assets would r...</td>\n",
       "      <td>NextEraEnergyZeroCarbonBlueprint</td>\n",
       "      <td>irr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77277</th>\n",
       "      <td>77277</td>\n",
       "      <td>→ Vehicle fleet conversions are based on the a...</td>\n",
       "      <td>NextEraEnergyZeroCarbonBlueprint</td>\n",
       "      <td>irr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77277 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         key                                          sentences  \\\n",
       "1          1  In 2021, 9.6% of our purchased electricity cam...   \n",
       "2          2  A large portion of this renewable electricity ...   \n",
       "3          3  From 2012 to 2020, we achieved a 26% reduction...   \n",
       "4          4  In 2021, we achieved a 9% absolute emissions r...   \n",
       "5          5  This reduction was partially driven by energy ...   \n",
       "...      ...                                                ...   \n",
       "77273  77273  → FPL’s four nuclear units continue to operate...   \n",
       "77274  77274  Technology We assume that: → FPL’s gas plants ...   \n",
       "77275  77275  → NextEra Energy Resources would invest in ele...   \n",
       "77276  77276  → All non-FPL fossil generation assets would r...   \n",
       "77277  77277  → Vehicle fleet conversions are based on the a...   \n",
       "\n",
       "                          company_label label  \n",
       "1                              EliLilly   rel  \n",
       "2                              EliLilly   rel  \n",
       "3                              EliLilly   rel  \n",
       "4                              EliLilly   rel  \n",
       "5                              EliLilly   rel  \n",
       "...                                 ...   ...  \n",
       "77273  NextEraEnergyZeroCarbonBlueprint   irr  \n",
       "77274  NextEraEnergyZeroCarbonBlueprint   irr  \n",
       "77275  NextEraEnergyZeroCarbonBlueprint   irr  \n",
       "77276  NextEraEnergyZeroCarbonBlueprint   irr  \n",
       "77277  NextEraEnergyZeroCarbonBlueprint   irr  \n",
       "\n",
       "[77277 rows x 4 columns]"
      ]
     },
     "execution_count": 920,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>irr</th>\n",
       "      <td>76430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rel</th>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key\n",
       "label       \n",
       "irr    76430\n",
       "rel      847"
      ]
     },
     "execution_count": 921,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sent.drop_duplicates('sentences').groupby('label').count()[['key']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save extracted_relevant_sentences, extracted_irrelevant_sentences, all_sentences with keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = all_sent[all_sent.label == 'rel']\n",
    "irr = all_sent[all_sent.label == 'irr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent.to_csv('all_sentences.csv', encoding = 'utf-8-sig')\n",
    "rel.to_csv(\"extracted_relevant_sentences.csv\", encoding = 'utf-8-sig')\n",
    "irr.to_csv(\"extracted_irrelevant_sentences.csv\", encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>irr</th>\n",
       "      <td>76430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rel</th>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key\n",
       "label       \n",
       "irr    76430\n",
       "rel      847"
      ]
     },
     "execution_count": 924,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sent.groupby('label').count()[['key']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Update Sentences Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_from_all = rel_from_all.rename(columns = {'original_rel': 'relevant_sentences'})\n",
    "# irr_from_all = irr_from_all.rename(columns = {'matched_rel_only': 'irrelevant_sentences'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_from_all = rel_from_all[['relevant_sentences', 'company_label']]\n",
    "# irr_from_all = irr_from_all[['irrelevant_sentences', 'company_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_from_all = rel.rename(columns = {'sentences': 'relevant_sentences'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [],
   "source": [
    "irr_from_all = irr.rename(columns = {'sentences': 'irrelevant_sentences'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_relevant_stat = rel_from_all.groupby('company_label', sort = False).count()[['relevant_sentences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_irrelevant_stat = irr_from_all.groupby('company_label', sort = False).count()[['irrelevant_sentences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_stat_final = total_irrelevant_stat.merge(total_relevant_stat, how = 'left', on = 'company_label', sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_stat_final['relevant_sentences'] = total_stat_final['relevant_sentences'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_stat_final['relevant_sentences'] = total_stat_final['relevant_sentences'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_stat_final['rel/total percentages'] = round((total_stat_final['relevant_sentences'] / (total_stat_final['relevant_sentences'] + total_stat_final['irrelevant_sentences'])) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_stat_final.to_csv('total_stat_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "irrelevant_sentences     76430.00\n",
       "relevant_sentences         847.00\n",
       "rel/total percentages      116.21\n",
       "dtype: float64"
      ]
     },
     "execution_count": 936,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_stat_final.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the sentence dictionary into json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dict = {}\n",
    "\n",
    "for key, sent in zip(all_sent.key, all_sent.sentences):\n",
    "    sent_dict[key] = sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('sentence_dict.json', 'w') as fp:\n",
    "    json.dump(sent_dict, fp, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentence_dict.json', 'r') as fp:\n",
    "    data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/tylerryoo/t3/extracted_sentences/notebooks/final_extracted_statistics_notebooks'\n",
    "files = glob.glob(path + \"/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [],
   "source": [
    "files.append('/Users/tylerryoo/t3/extracted_sentences/notebooks/final_extracted_statistics_notebooks/sentence_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/tylerryoo/t3/extracted_sentences/notebooks/final_extracted_statistics_notebooks/total_stat_final.csv',\n",
       " '/Users/tylerryoo/t3/extracted_sentences/notebooks/final_extracted_statistics_notebooks/all_sentences.csv',\n",
       " '/Users/tylerryoo/t3/extracted_sentences/notebooks/final_extracted_statistics_notebooks/string_matched.csv',\n",
       " '/Users/tylerryoo/t3/extracted_sentences/notebooks/final_extracted_statistics_notebooks/extracted_relevant_sentences.csv',\n",
       " '/Users/tylerryoo/t3/extracted_sentences/notebooks/final_extracted_statistics_notebooks/sentences_matched.csv',\n",
       " '/Users/tylerryoo/t3/extracted_sentences/notebooks/final_extracted_statistics_notebooks/sentenences_not_matched.csv',\n",
       " '/Users/tylerryoo/t3/extracted_sentences/notebooks/final_extracted_statistics_notebooks/extracted_irrelevant_sentences.csv',\n",
       " '/Users/tylerryoo/t3/extracted_sentences/notebooks/final_extracted_statistics_notebooks/sentence_dict.json']"
      ]
     },
     "execution_count": 951,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    \n",
    "    if file == '/Users/tylerryoo/t3/extracted_sentences/notebooks/final_extracted_statistics_notebooks/string_matched.csv':\n",
    "        continue\n",
    "\n",
    "    filename = file.split('/')[-1]\n",
    "    \n",
    "    target = (r'/Users/tylerryoo/t3/relevant_irrelevant_sentences_labeled_final/' + filename)\n",
    "\n",
    "    shutil.move(file, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Previous Method to Separate relevant and irrelevant sentences --> also reordering sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_extract_relevant = []\n",
    "# test_extract_relevant_label = []\n",
    "# test_extract_irrelevant = []\n",
    "# test_extract_irrelevant_label = []\n",
    "\n",
    "# for sent, lab in zip(all_var, all_lab):\n",
    "#     if sent in sentences_matched.matched_rel_only.to_list():\n",
    "#         test_extract_relevant.append(sent)\n",
    "#         test_extract_relevant_label.append(lab)\n",
    "#     elif sent not in sentences_matched.matched_rel_only.to_list():\n",
    "#         test_extract_irrelevant.append(sent)\n",
    "#         test_extract_irrelevant_label.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(test_extract_relevant), len(test_extract_relevant_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(test_extract_irrelevant), len(test_extract_irrelevant_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTION: Make sure to match rel_from_all and extract_rel_var --> to preserve the order of relevant sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_from_all = pd.DataFrame(list(zip(test_extract_relevant, test_extract_relevant_label)), columns = ['relevant_sentences', 'company_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_from_all_reorder = rel_from_all.rename(columns = {'relevant_sentences': 'matched_rel_only'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_from_all_reorder = rel_from_all_reorder.merge(sentences_matched, how = 'left', on = ['matched_rel_only', 'company_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_from_all_reorder[rel_from_all_reorder.company_label == 'Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed instances where more null values from original relevant sentences were observed but discard them as they are considered irrelevant\n",
    "# for i in rel_from_all_reorder[rel_from_all_reorder.original_rel.isnull()]['matched_rel_only']:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  #remove null values after merge --> sentences were irrelevant\n",
    "# rel_from_all_reorder = rel_from_all_reorder[rel_from_all_reorder.original_rel.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_from_all_reorder = rel_from_all_reorder[['original_rel', 'matched_rel_only', 'company_label']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# irr_from_all = pd.DataFrame(list(zip(test_extract_irrelevant, test_extract_irrelevant_label)),  columns = ['irrelevant_sentences', 'company_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# org_rel = pd.DataFrame(list(zip(sentences_matched.original_rel, sentences_matched.company_label)), columns = ['relevant_sentences', 'company_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(rel_from_all_reorder), len(irr_from_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the final version of relevant sentences\n",
    "# pd.DataFrame(rel_from_all).to_csv(\"extracted_relevant_sentences.csv\", encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final version of irrelevant sentences\n",
    "# pd.DataFrame(irr_from_all).to_csv(\"extracted_irrelevant_sentences.csv\", encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final version of relevant sentences\n",
    "# pd.DataFrame(org_rel).to_csv(\"extracted_relevant_sentences.csv\", encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove sentences that are shorter than 10 (these are irrelevant sentences)\n",
    "# still_not_matched = still_not_matched[still_not_matched['sent_count'] >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more_match = []\n",
    "# org_rel = []\n",
    "# track = 0\n",
    "# for i, j in zip(still_not_matched.original_rel, still_not_matched.company_label):\n",
    "#     val = process.extractOne(i.lower(), [i.lower() for i in all_var], scorer = fuzz.partial_ratio)\n",
    "#     more_match.append(val)\n",
    "#     org_rel.append(i)\n",
    "#     print(track, end = \" \")\n",
    "#     track += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more_match_above = []\n",
    "# for i, j in zip(more_match, org_rel):\n",
    "#     if i[1] >= 80:\n",
    "#         print(i)\n",
    "#         print()\n",
    "#         print(j)\n",
    "#         print()\n",
    "# #         more_match_above.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_rel_var = []\n",
    "# extract_mat1 = []\n",
    "\n",
    "# # extracting relevant sentences with ratio greater than 90\n",
    "# for i, j in zip(mat1, rel_var):\n",
    "#     if i is None:\n",
    "#         continue\n",
    "#     elif i[1] >= 90:\n",
    "#         extract_rel_var.append(j) # original relevant sentences\n",
    "#         extract_mat1.append(i) # relevant sentences from all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_mat1 = []\n",
    "# extract_mat_label = []\n",
    "\n",
    "# for i, j in zip(mat1, matlabel):\n",
    "#     if i is None:\n",
    "#         continue\n",
    "#     elif i[1] >= 90:\n",
    "#         extract_mat_label.append(j) # relevant sentences comp labels\n",
    "#         extract_mat1.append(i) # relevant sentences from all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(extract_mat1), len(extract_mat_label), len(extract_rel_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only saving extracted relevant sentences without ratio values  \n",
    "# rel_from_all = []\n",
    "# for i in extract_mat1:\n",
    "#     rel_from_all.append(i[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "db1c1e886ca7e5218f158543d1b9804c0a5c522f5654be9e23cd8543b350db84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
