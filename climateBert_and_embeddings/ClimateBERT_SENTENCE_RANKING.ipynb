{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7f30ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import PyPDF2\n",
    "import nltk\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e76c907",
   "metadata": {},
   "source": [
    "# Extracting PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66671123",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"Reports\\EliLilly_2021_Environmental_ESG_report.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "327ebcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfReader = PyPDF2.PdfFileReader(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf979c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(pdfReader.pages)\n",
    "txt = ''\n",
    "for i in range(n):\n",
    "    temp = pdfReader.pages[i].extractText()\n",
    "    txt = txt + temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e2bc4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing '\\n' tokens\n",
    "tokens = nltk.sent_tokenize(txt.replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a9e22d",
   "metadata": {},
   "source": [
    "# Preprocessing String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6601785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving new name for preprocess strings\n",
    "#keeping only sentences with length greater than 3\n",
    "pre_tokens = []\n",
    "for sen in tokens:\n",
    "    if len(sen.split(' ')) > 3:\n",
    "        pre_tokens.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "380602cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"climatebert/distilroberta-base-climate-f\")\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"climatebert/distilroberta-base-climate-f\",output_hidden_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6354eebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForMaskedLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50500, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=50500, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a1cb7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input embedding matrix\n",
    "a = model.roberta.get_input_embeddings().weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae227777",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences = ['Our investments in efficiency helped us achieve a 22% reduction in the carbon dioxide emitted for each dollar of revenue we earned, compared to 2019',\n",
    "             'In 2021, we increased the amount of renewable energy in our purchased electricity to 79% compared to 41% in 2020',\n",
    "             'Taking Root’s CommuniTree reforestation in Nicaragua —the largest such project in the country—partners with farming families to help develop sustainable livelihoods by growing native tree species on marginal farmland. The United Nations and the European Union have used this project as a model for reforestation.']\n",
    "target = []\n",
    "for ids,sen in enumerate(sentences):\n",
    "\n",
    "    marked_text = \"[CLS] \" + sen + \" [SEP]\"\n",
    "    # Split the sentence into tokens.\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "\n",
    "    # Map the token strings to their vocabulary indeces.\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "\n",
    "    #creating segment ids for the sentence\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    hidden_states = []\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        # Evaluating the model will return a different number of objects based on \n",
    "        # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "        # becase we set `output_hidden_states = True`, the third item will be the \n",
    "        # hidden states from all layers. See the documentation for more details:\n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "        hidden_states = outputs[-1]\n",
    "\n",
    "\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "\n",
    "    # Calculate the average of all 22 token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "    \n",
    "    target.append(sentence_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34ccb7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for ids,sen in enumerate(pre_tokens):\n",
    "\n",
    "    marked_text = \"[CLS] \" + sen + \" [SEP]\"\n",
    "    # Split the sentence into tokens.\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "\n",
    "    # Map the token strings to their vocabulary indeces.\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "\n",
    "    #creating segment ids for the sentence\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    hidden_states = []\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        # Evaluating the model will return a different number of objects based on \n",
    "        # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "        # becase we set `output_hidden_states = True`, the third item will be the \n",
    "        # hidden states from all layers. See the documentation for more details:\n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "        hidden_states = outputs[-1]\n",
    "\n",
    "\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "\n",
    "    # Calculate the average of all 22 token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "    corpus.append(sentence_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af165801",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.stack(corpus)\n",
    "all_embeddings = a\n",
    "normed_embeddings = (all_embeddings.T / (all_embeddings**2).sum(axis=1) ** 0.5).T\n",
    "indexer = KDTree(normed_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f7711a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[]\n",
    "for emb in zip(target,sentences):\n",
    "    top_10 = indexer.query(emb[0].reshape(1, -1),return_distance = False, k = 10)\n",
    "#     print(top_20)\n",
    "    result.append([emb[1],np.array(pre_tokens)[top_10]])\n",
    "    result.append(['----------------------------------end of example--------------------------------------------------'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "913819c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Our investments in efficiency helped us achieve a 22% reduction in the carbon dioxide emitted for each dollar of revenue we earned, compared to 2019',\n",
       "  array([['From 2012 to 2020, we achieved a 26% reduction in absolute emissions.',\n",
       "          'In 2021, we reduced our energy consumption by 2.9%, and we reduced our absolute GHGemissions by 9% compared to 2020.',\n",
       "          'The solar array is expected toprovide up to 15% of the site’s purchased electricity, resulting in an estimated 2,350 t onne reduction in the site’s annualcarbon footprint.',\n",
       "          'Become carbon neutral in our own operations (Scope 1 and 2 emissions)Lilly strives to be carbon neutral by 2030, and we are working to drive GHG emissions reductions throughout our operations.',\n",
       "          'Reducing Our Energy Use EmissionsWe continue to evaluate how to improve our energy resiliency and expand our use of r enewable electricity consistent with our goal t odiversify our energy sources and decrease our GHG emissions over time.',\n",
       "          'We’re committed to reducing our environmental footprint across the life cycles ofour products and our supply chain.',\n",
       "          'In 2021, we achie ved a 9% absoluteemissions reduction versus 2020.',\n",
       "          'This reduction was partially driven by energy e\\x00ciency improvements and an increase in theuse of renewable electricity including the  startup of our solar array in Kinsale.',\n",
       "          'We are working on calculating our Scope 3 emissions and identifying climate-r elated risks andopportunities in our business and intend t o develop measurable Scope 3 goals.',\n",
       "          'The combined heat and power (CHP) system will signi\\x00cantly impr ove theresiliency of our Puerto Rico manufacturing operations and will also result in lower energy expenses and reduced GHGemissions.']],\n",
       "        dtype='<U1244')],\n",
       " ['----------------------------------end of example--------------------------------------------------'],\n",
       " ['In 2021, we increased the amount of renewable energy in our purchased electricity to 79% compared to 41% in 2020',\n",
       "  array([['In 2021, we reduced our energy consumption by 2.9%, and we reduced our absolute GHGemissions by 9% compared to 2020.',\n",
       "          'Projects are also assessed on theirpotential to scale in other areas across the company.Enhancing the Use of SolarIn 2021, 9.6% of our purchased electricity was secur ed from renewable sources.',\n",
       "          'From 2012 to 2020, we achieved a 26% reduction in absolute emissions.',\n",
       "          'The solar array is expected toprovide up to 15% of the site’s purchased electricity, resulting in an estimated 2,350 t onne reduction in the site’s annualcarbon footprint.',\n",
       "          'This reduction was partially driven by energy e\\x00ciency improvements and an increase in theuse of renewable electricity including the  startup of our solar array in Kinsale.',\n",
       "          'Data includes energy from purchased electricity, steam and chilled water.View Lilly’s environmental data from 2020, including our previous goals and progress through 2020.',\n",
       "          'Become carbon neutral in our own operations (Scope 1 and 2 emissions)Lilly strives to be carbon neutral by 2030, and we are working to drive GHG emissions reductions throughout our operations.',\n",
       "          'In 2021, we achie ved a 9% absoluteemissions reduction versus 2020.',\n",
       "          'Reducing Our Energy Use EmissionsWe continue to evaluate how to improve our energy resiliency and expand our use of r enewable electricity consistent with our goal t odiversify our energy sources and decrease our GHG emissions over time.',\n",
       "          'Our emissions reductionswere driven by a combination of energy and process e\\x00ciencies, and changes in our ener gy supply mix to include cleaner energysources.']],\n",
       "        dtype='<U1244')],\n",
       " ['----------------------------------end of example--------------------------------------------------'],\n",
       " ['Taking Root’s CommuniTree reforestation in Nicaragua —the largest such project in the country—partners with farming families to help develop sustainable livelihoods by growing native tree species on marginal farmland. The United Nations and the European Union have used this project as a model for reforestation.',\n",
       "  array([['We plan to increase the amountof renewable electricity utilized as we advance new projects, including solar arrays at our sites in Puerto Rico and France, and anexpansion to our solar array in Kinsale, Ireland, and another solar array in Alcobendas, Spain.',\n",
       "          'These projects include: Kinsale – In July, 2021, Lilly started up a 20-acre solar array in Kinsale, Ireland consisting of over 12,600 solar panels,which at the time of construction r epresented the largest solar development in Ireland.',\n",
       "          'These pr ojects are expected to reduce energy consumption by over12,500 MWh per year.Encouraging Eco-E\\x00ciency Across Our OperationsIn 2006, we established the Ener gy, Waste and Water Reduction Fund to encourage projects that demonstrate the greatestpotential for reductions in emissions and ener gy use but are not funded by site capital budgets.',\n",
       "          'One of our sites in Puerto Rico implemented the \\x00rst phase of a chilled water andcooling tower optimization project, and another site began a substantial e\\x00ciency upgr ade to its chilled water systemthat is expected to be completed in mid-2022.',\n",
       "          'Projects are also assessed on theirpotential to scale in other areas across the company.Enhancing the Use of SolarIn 2021, 9.6% of our purchased electricity was secur ed from renewable sources.',\n",
       "          'Collectively, we expect that these projects will reduce energy consumption by anestimated 14,000 MWh per y ear.Chiller System Optimization  – Chilled water and cooling systems ar e some of the highest energy consuming systemsin pharmaceutical operations, and they continued to be a focus for our engineering r esources in 2021.',\n",
       "          'We also operate combined heat and power systems at our manufacturing sites in Kinsale, Ir eland and Sesto,Italy.Fleet Fuel EconomyOur GREENDirections program focuses on \\x00eet fuel economy and GHG emissions, o\\x00ce ener gy conservation and wastereduction for our sales and mark eting a\\x00liates around the world.',\n",
       "          'The 40-kW capacity solar panels will help r educe Lilly’s carbon footprint in the city – a k ey priority due to risingpollution levels.',\n",
       "          'The solar panels supply appr oximately 10% of the site’s energy needs.Manufacturing facilities in Fegersheim, France and Sesto, Italy have solar arrays of 62 kW and 145 kW, respectively.Additional solar capacity is being installed at our manufacturing facilities in Puer to Rico and Fegersheim.Energy ResiliencyIn 2017, we began designing a new 9 megawatt (MW ) combined heat and power system at our Puer to Rico facility, whichsuccessfully commenced oper ation in 2021.',\n",
       "          'The combined heat and power (CHP) system will signi\\x00cantly impr ove theresiliency of our Puerto Rico manufacturing operations and will also result in lower energy expenses and reduced GHGemissions.']],\n",
       "        dtype='<U1244')],\n",
       " ['----------------------------------end of example--------------------------------------------------']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6d89b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ac0299e59e0d70458a5970d26bf8f33138a0c4c728eb3df577e6d5038f0a507"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
